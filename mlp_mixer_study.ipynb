{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgJ6dSF10qPO"
      },
      "source": [
        "# Performance Evaluation, Hyperparameter Optimization, and Ablation Study of MLP-Mixer Model on the MNIST Dataset\n",
        "In this notebook,I have trained a MLP-Mixer model to classify MNIST digits using **PyTorch**. In addition I have performed model tuning,  conducted baseline model comparison with CNN and simple MLP and did an ablation study to investigate the importance of different components of the MLP-Mixer model.\n",
        "\n",
        "First, the needed imports. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRByqjw50qPQ",
        "outputId": "650046ae-b4c2-44d5-ddde-abfc7c254d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version: 2.0.0+cu118  Device: cuda\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    \n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfNVA_cV0qPR"
      },
      "source": [
        "## Data\n",
        "\n",
        "Next we'll load the MNIST data.  First time we may have to download the data, which can take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFnPqVv40qPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d799aa-0f96-4d04-fda3-4c8da7f70eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 102817030.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 20625863.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26155244.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4770981.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', \n",
        "                               train=True, \n",
        "                               download=True, \n",
        "                               transform=transforms.ToTensor())\n",
        "\n",
        "validation_dataset = datasets.MNIST('./data', \n",
        "                                    train=False, \n",
        "                                    transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, \n",
        "                                                batch_size=batch_size, \n",
        "                                                shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg3sFK-o0qPS"
      },
      "source": [
        "The train and test data are provided via data loaders that provide iterators over the datasets. The first element of training data (`X_train`) is a 4th-order tensor of size (`batch_size`, 1, 28, 28), i.e. it consists of a batch of images of size 1x28x28 pixels. `y_train` is a vector containing the correct classes (\"0\", \"1\", ..., \"9\") for each training digit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcAIMM4e0qPS",
        "outputId": "dc0337d8-c60b-44be-9168-56688cc99e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
            "y_train: torch.Size([32]) type: torch.LongTensor\n"
          ]
        }
      ],
      "source": [
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CvTydhW0qPT"
      },
      "source": [
        "Here are the first 10 training digits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "IOvGQFtl0qPT",
        "outputId": "d1d40984-d9c4-4c0a-ca7e-c7e875d05832"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "pltsize=1\n",
        "plt.figure(figsize=(10*pltsize, pltsize))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1,10,i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray_r\")\n",
        "    plt.title('Class: '+str(y_train[i].item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbRpmJJA0qPU"
      },
      "source": [
        "## MLP-Mixer Model\n",
        "\n",
        "Here, let us define the MLP-Mixer Model as a Python class.  We have to write the `__init__()` and `forward()` methods, and PyTorch will automatically generate a `backward()` method for computing the gradients for the backward pass."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hcurXET4gXQ",
        "outputId": "aaa36d51-ccf1-4e99-f639-244a0f30ddc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from einops.layers.torch import Rearrange\n"
      ],
      "metadata": {
        "id": "wNevNMRc4kIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaK7_c4J0qPU",
        "outputId": "2893ee9f-8b25-49ec-9aa3-103415deda65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPMixer(\n",
            "  (to_patch_embedding): Sequential(\n",
            "    (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=7, p2=7)\n",
            "    (1): Linear(in_features=49, out_features=64, bias=True)\n",
            "  )\n",
            "  (network): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): MixerBlock(\n",
            "        (pre_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (token_mixer): Sequential(\n",
            "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=16, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (channel_mixer): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): MixerBlock(\n",
            "        (pre_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (token_mixer): Sequential(\n",
            "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=16, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (channel_mixer): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): MixerBlock(\n",
            "        (pre_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (token_mixer): Sequential(\n",
            "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=16, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (channel_mixer): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): MixerBlock(\n",
            "        (pre_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (token_mixer): Sequential(\n",
            "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=16, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (channel_mixer): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): MixerBlock(\n",
            "        (pre_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (token_mixer): Sequential(\n",
            "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=16, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (channel_mixer): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): MixerBlock(\n",
            "        (pre_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (token_mixer): Sequential(\n",
            "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=16, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (channel_mixer): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): MixerBlock(\n",
            "        (pre_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (token_mixer): Sequential(\n",
            "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=16, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (channel_mixer): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): MixerBlock(\n",
            "        (pre_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (token_mixer): Sequential(\n",
            "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=16, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (channel_mixer): Sequential(\n",
            "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.1, inplace=False)\n",
            "          (3): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (4): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
            "  (classifier): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class MixerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_patches):\n",
        "        super().__init__()\n",
        "        self.pre_layer_norm = nn.LayerNorm(dim)\n",
        "        self.post_layer_norm = nn.LayerNorm(dim)\n",
        "        \n",
        "        self.token_mixer = nn.Sequential(\n",
        "                            nn.Linear(num_patches, dim),\n",
        "                            nn.GELU(),\n",
        "                            nn.Dropout(0.1),\n",
        "                            nn.Linear(dim, num_patches),\n",
        "                            nn.Dropout(0.1)\n",
        "                            )\n",
        "        \n",
        "        self.channel_mixer = nn.Sequential(\n",
        "                            nn.Linear(dim, dim),\n",
        "                            nn.GELU(),\n",
        "                            nn.Dropout(0.1),\n",
        "                            nn.Linear(dim, dim),\n",
        "                            nn.Dropout(0.1)\n",
        "                            )\n",
        "                            \n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        pre_ln =self.pre_layer_norm(x)\n",
        "        tm_out = self.token_mixer(pre_ln.transpose(1,2)).transpose(1,2)\n",
        "        tm_out = tm_out + x\n",
        "        post_ln = self.post_layer_norm(tm_out)\n",
        "        cm_out = self.channel_mixer(post_ln)+tm_out\n",
        "        return cm_out\n",
        "        \n",
        "class MLPMixer(nn.Module):\n",
        "    def __init__(self, input_size, patch_size, dim=512, img_channel=1, layers=12, num_classes=10):\n",
        "        super().__init__()\n",
        "        assert (input_size[0] % patch_size[0]) == 0, 'H must be divisible by patch size'\n",
        "        assert (input_size[1] % patch_size[1]) == 0, 'W must be divisible by patch size'\n",
        "        num_patches = int(input_size[0] / patch_size[0] * input_size[1] / patch_size[1])\n",
        "        patch_dim = img_channel * patch_size[0] * patch_size[1]\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_size[0], p2=patch_size[1]),\n",
        "            nn.Linear(patch_dim, dim))\n",
        "\n",
        "        self.network = nn.Sequential(*[nn.Sequential(MixerBlock(dim, num_patches)) for _ in range(layers)])\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.classifier = nn.Linear(dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.to_patch_embedding(x)\n",
        "        x = self.network(x)\n",
        "        return self.classifier(self.pool(x.transpose(1, 2)).squeeze(2))\n",
        "\n",
        "\n",
        "model = MLPMixer(input_size=(28, 28), patch_size=(7, 7), dim=64, img_channel=1, layers=8, num_classes=10).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZmHUOl80qPU"
      },
      "source": [
        "## Learning\n",
        "\n",
        "Let's now define functions to `train()` and `validate()` the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sjl2tex0qPV"
      },
      "outputs": [],
      "source": [
        "def train(epoch, log_interval=200):\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Loop over each batch from the training set\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Copy data to GPU if needed\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Zero gradient buffers\n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        # Pass data through the network\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D5wdJQj0qPV"
      },
      "outputs": [],
      "source": [
        "def validate(loss_vector, accuracy_vector):\n",
        "    model.eval()\n",
        "    val_loss, correct = 0, 0\n",
        "    for data, target in validation_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        val_loss += criterion(output, target).data.item()\n",
        "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "\n",
        "    val_loss /= len(validation_loader)\n",
        "    loss_vector.append(val_loss)\n",
        "\n",
        "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
        "    accuracy_vector.append(accuracy)\n",
        "    \n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        val_loss, correct, len(validation_loader.dataset), accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBs2mnXc0qPV"
      },
      "source": [
        "Now we are ready to train our model using the `train()` function.  An *epoch* means one pass through the whole training data. After each epoch, we evaluate the model using `validate()`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tphIFVny0qPV",
        "outputId": "15643d5b-2bd6-40c5-b3e4-f9776e1424e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.282989\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.733439\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.875557\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.482106\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.336965\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.271522\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.331845\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.244410\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.305640\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.183626\n",
            "\n",
            "Validation set: Average loss: 0.1917, Accuracy: 9393/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.151155\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.164452\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.363307\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.189698\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.306863\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.156385\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.123855\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.141879\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.166428\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.218549\n",
            "\n",
            "Validation set: Average loss: 0.1371, Accuracy: 9558/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.380152\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.020287\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.046425\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.228319\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.199835\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.128603\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.269206\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.193300\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.081528\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.017102\n",
            "\n",
            "Validation set: Average loss: 0.1140, Accuracy: 9617/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.032994\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.188405\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.040689\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.196242\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.140818\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.060258\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.238248\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.197826\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.225296\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.166186\n",
            "\n",
            "Validation set: Average loss: 0.0994, Accuracy: 9693/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.138960\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.014551\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.225089\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.013557\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.070326\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.066577\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.255947\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.219561\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.136909\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.119550\n",
            "\n",
            "Validation set: Average loss: 0.0920, Accuracy: 9690/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.045949\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.061516\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.057846\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.085516\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.103576\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.046185\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.086307\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.123554\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.202112\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.114633\n",
            "\n",
            "Validation set: Average loss: 0.0865, Accuracy: 9715/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.025179\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.139943\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.266025\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.035076\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.027785\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.018468\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.006332\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.060619\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.005157\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.140236\n",
            "\n",
            "Validation set: Average loss: 0.0792, Accuracy: 9734/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.180274\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.028617\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.047244\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.054091\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.254103\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.096662\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.081314\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.049206\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.027163\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.209861\n",
            "\n",
            "Validation set: Average loss: 0.0785, Accuracy: 9739/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.086078\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.005150\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.202035\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.015766\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.100711\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.045125\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.553514\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.035310\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.048556\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.015526\n",
            "\n",
            "Validation set: Average loss: 0.0743, Accuracy: 9754/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.057434\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.076455\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.026332\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.023544\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.173384\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.115030\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.008968\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.120248\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.033736\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.006977\n",
            "\n",
            "Validation set: Average loss: 0.0735, Accuracy: 9751/10000 (98%)\n",
            "\n",
            "CPU times: user 5min 29s, sys: 1.94 s, total: 5min 31s\n",
            "Wall time: 5min 38s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "epochs = 10\n",
        "\n",
        "lossv, accv = [], []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    validate(lossv, accv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsiKi1Go0qPW"
      },
      "source": [
        "Let's now visualize how the training progressed. \n",
        "\n",
        "* *Loss* is a function of the difference of the network output and the target values.  We are minimizing the loss function during training so it should decrease over time.\n",
        "* *Accuracy* is the classification accuracy for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "9jGJ2Lrc0qPW",
        "outputId": "300abd09-6def-45e0-dadb-e13ecb3d48ad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAEpCAYAAAAEbvI5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCfUlEQVR4nO3de1yUZf4//tcwwDAMZzkfFQjwkAdQCfK4kui65oFaJfOAWrut5mljN/v8Mlszyra+bmWau6UueEpdMzuIRImaGIia4hlSOR8FhuPAzNy/P9CpCVCGoJlhXs/H437I3HPd9/2+74yX931f132LBEEQQEREZGLM9F0AERGRPjAAiYjIJDEAiYjIJDEAiYjIJDEAiYjIJDEAiYjIJDEAiYjIJDEAiYjIJDEAiYjIJDEAqVfbvn07RCIRbt26pZk3btw4jBs37oHLHjt2DCKRCMeOHevWmkQiEdauXdut6yQi3TEAiXrAl19+yZAjMnDm+i6A6Ld29OjRHt/Gl19+iU2bNrUbgo2NjTA35/96RPrGM0AyOZaWlrC0tNTb9q2srBiAndDQ0KDvEqiXYwCSwdi/fz9EIhHS0tLafPfhhx9CJBIhOzsbAHDhwgUsWLAA/v7+sLKygru7OxYuXIjKysoHbqe9e4AFBQWYPn06ZDIZXF1dsXLlSigUijbLnjhxAk8++SR8fX0hkUjg4+ODlStXorGxUdNmwYIF2LRpE4DW+333pnvauwd47tw5TJ48GXZ2drCxscGECRNw+vRprTb37md+9913WLVqFVxcXCCTyTBjxgyUl5c/cL91OWaFhYVYtGgRPD09IZFI0K9fPzz33HNobm7WtKmursbKlSvRt29fSCQSeHt7Y968eaioqNCq9+f3X4H2762OGzcOgwYNQlZWFsaMGQNra2u89NJLAIBDhw5hypQpmloCAgKwbt06qFSqNnV///33+P3vfw9HR0fIZDIMHjwY//rXvwAA27Ztg0gkwrlz59os9/rrr0MsFqOwsPCBx5F6D/4zlAzGlClTYGNjg08++QRjx47V+m7v3r0YOHAgBg0aBABISUnBjz/+iLi4OLi7u+PSpUvYunUrLl26hNOnT2sFzoM0NjZiwoQJyMvLw7Jly+Dp6YnExER88803bdru27cPDQ0NeO6559CnTx9kZGTgvffeQ0FBAfbt2wcA+NOf/oSioiKkpKQgMTHxgdu/dOkSRo8eDTs7O/ztb3+DhYUFPvzwQ4wbNw5paWkIDw/Xav/888/D0dERr7zyCm7duoWNGzdi6dKl2Lt3732309ljVlRUhJEjR6K6uhrPPvssQkJCUFhYiP3796OhoQGWlpaoq6vD6NGjceXKFSxcuBChoaGoqKjAZ599hoKCAjg7O3f28GtUVlZi8uTJmD17Np5++mm4ubkBaA1SGxsbrFq1CjY2Nvjmm2+wZs0ayOVyvPXWW1r794c//AEeHh5Yvnw53N3dceXKFXz++edYvnw5nnjiCSxZsgQ7d+7EsGHDtLa9c+dOjBs3Dl5eXjrXTUZMIDIgsbGxgqurq6BUKjXziouLBTMzM+Ef//iHZl5DQ0ObZXfv3i0AEI4fP66Zt23bNgGAcPPmTc28sWPHCmPHjtV83rhxowBA+OSTTzTz6uvrhcDAQAGA8O233953uwkJCYJIJBJu376tmbdkyRKho/+9AAivvPKK5vP06dMFS0tLITc3VzOvqKhIsLW1FcaMGdNmX6KiogS1Wq2Zv3LlSkEsFgvV1dXtbu9+tbd3zObNmyeYmZkJmZmZbdrf2+6aNWsEAML//ve/Dtu0d+wFQRC+/fbbNsd17NixAgBhy5Ytnar7T3/6k2BtbS00NTUJgiAISqVS6Nevn+Dn5ydUVVW1W48gtP798vT0FFQqlWbe2bNnBQDCtm3b2myHejdeAiWDMmvWLJSVlWldHtu/fz/UajVmzZqlmSeVSjU/NzU1oaKiAo888ggA4OzZszpt88svv4SHhweeeOIJzTxra2s8++yzbdr+fLv19fWoqKhAZGQkBEFo99Lag6hUKhw9ehTTp0+Hv7+/Zr6HhweeeuopnDx5EnK5XGuZZ599VusMd/To0VCpVLh9+/Z9t9WZY6ZWq/Hpp59i6tSpGD58eJt13NvugQMHMGTIEMyYMaPDNrqSSCSIi4u7b921tbWoqKjA6NGj0dDQgKtXrwJovYR88+ZNrFixAg4ODh3WM2/ePBQVFeHbb7/VzNu5cyekUiliYmK6VDcZLwYgGZRJkybB3t5e63Le3r17MXToUAQFBWnm3blzB8uXL4ebmxukUilcXFzQr18/AEBNTY1O27x9+zYCAwPb/OIODg5u0zYvLw8LFiyAk5MTbGxs4OLiorlcq+t2AaC8vBwNDQ3tbqt///5Qq9XIz8/Xmu/r66v12dHREQBQVVV132115piVl5dDLpdrLjV3JDc394FtdOXl5dVu56RLly5hxowZsLe3h52dHVxcXPD0009r1Z2bmwsAD6zpscceg4eHB3bu3AmgNfB3796NadOmwdbWtjt3h4wA7wGSQZFIJJg+fToOHjyIDz74AKWlpfjuu+/w+uuva7X74x//iFOnTiE+Ph5Dhw6FjY0N1Go1Jk2aBLVa3SO1qVQqPPbYY7hz5w7+/ve/IyQkBDKZDIWFhViwYEGPbfeXxGJxu/MFQbjvcr/1MevoTLC9ziuA9pnePdXV1Rg7dizs7Ozwj3/8AwEBAbCyssLZs2fx97//Xee6xWIxnnrqKfz73//GBx98gO+++w5FRUWaQCXTwgAkgzNr1izs2LEDqampuHLlCgRB0Lr8WVVVhdTUVLz66qtYs2aNZv6NGze6tD0/Pz9kZ2dDEAStX9rXrl3Tanfx4kVcv34dO3bswLx58zTzU1JS2qyzs5cBXVxcYG1t3WZbAHD16lWYmZnBx8ens7vSoc4eMxcXF9jZ2Wl623YkICDggW3unZlWV1drzX/QpdqfO3bsGCorK/G///0PY8aM0cy/efNmm3oAIDs7G1FRUfdd57x58/D222/j8OHD+Oqrr+Di4oLo6OhO10S9By+BksGJioqCk5MT9u7di71792LkyJGaS3XAT2dAvzzj2bhxY5e29/vf/x5FRUXYv3+/Zl5DQwO2bt2q1a697QqCoOlm/3MymQxA21/+vyQWizFx4kQcOnRIa7hAaWkpdu3ahVGjRsHOzk7XXWp3O7+sHWh7zMzMzDB9+nQcPnwYZ86cabOee8vHxMTghx9+wMGDBztscy+Ujh8/rvlOpVK1Oa661t3c3IwPPvhAq11oaCj69euHjRs3tjnmv9znwYMHY/DgwfjPf/6DAwcOYPbs2RyXaaL4X50MjoWFBWbOnIk9e/agvr4e//znP7W+t7Ozw5gxY7Bhwwa0tLTAy8sLR48ebXNW0FnPPPMM3n//fcybNw9ZWVnw8PBAYmIirK2ttdqFhIQgICAAL7zwAgoLC2FnZ4cDBw60e+8tLCwMALBs2TJER0dDLBZj9uzZ7W7/tddeQ0pKCkaNGoW//OUvMDc3x4cffgiFQoENGzZ0aZ9+SZdj9vrrr+Po0aMYO3Ysnn32WfTv3x/FxcXYt28fTp48CQcHB8THx2P//v148sknsXDhQoSFheHOnTv47LPPsGXLFgwZMgQDBw7EI488gtWrV+POnTtwcnLCnj17oFQqO113ZGQkHB0dMX/+fCxbtgwikQiJiYltQs3MzAybN2/G1KlTMXToUMTFxcHDwwNXr17FpUuXkJycrNV+3rx5eOGFFwCAlz9NmV76nhI9QEpKigBAEIlEQn5+fpvvCwoKhBkzZggODg6Cvb298OSTTwpFRUVthhh0ZhiEIAjC7du3hccff1ywtrYWnJ2dheXLlwtHjhxp013/8uXLQlRUlGBjYyM4OzsLzzzzjPDDDz+06UavVCqF559/XnBxcRFEIpHWkIhf1igIrV3xo6OjBRsbG8Ha2loYP368cOrUKa029/bll8MT2htW0J7OHrN7x2PevHmCi4uLIJFIBH9/f2HJkiWCQqHQtKmsrBSWLl0qeHl5CZaWloK3t7cwf/58oaKiQtMmNzdXiIqKEiQSieDm5ia89NJLmv+2vxwGMXDgwHbr/u6774RHHnlEkEqlgqenp/C3v/1NSE5ObnefT548KTz22GOCra2tIJPJhMGDBwvvvfdem3UWFxcLYrFYCAoKuu8xo95NJAgPuHNORNTLVFRUwMPDA2vWrMHLL7+s73JIT3gPkIhMzvbt26FSqTB37lx9l0J6xHuARGQyvvnmG1y+fBnr16/H9OnT0bdvX32XRHrES6BEZDLGjRuHU6dO4dFHH0VSUhKf/WniGIBERGSSeA+QiIhMEgOQiIhMUq/pBKNWq1FUVARbW9suP42eiIiMmyAIqK2thaenJ8zM7n+O12sCsKioqFuemUhERMYvPz8f3t7e923TawLw3qtM8vPzu+XZiUREZHzkcjl8fHw69XqrXhOA9y572tnZMQCJiExcZ26FsRMMERGZJAYgERGZJAYgERGZJAYgERGZJAYgERGZJAYgERGZJJ0DsLa2FitWrICfnx+kUikiIyORmZmp+V4kErU7vfXWWx2uc+3atW3ah4SEdG2PiIioXSU1TUjPrcS5vCpcK6lF/p0GVNYp0NSigim+F0HncYCLFy9GdnY2EhMT4enpiaSkJERFReHy5cvw8vJCcXGxVvuvvvoKixYtQkxMzH3XO3DgQHz99dc/FWbea4YoEhH95pqValwqqsHZvGqczavCudtVKKpp6rC9SARYW4hhLTGHtaUY1pb3/hRrPkstxZBZiiG1NIfs7vx7P0stxZBJzCG1aJ0vk7S2t7YQw1xsmBcbdUqZxsZGHDhwAIcOHcKYMWMAtJ69HT58GJs3b8Zrr70Gd3d3rWUOHTqE8ePHw9/f//6FmJu3WZaIiDqnVN6Es7ercDavCmfzqnGxsAbNSrVWGzMR4NdHhhaVGo3NKtQ3K9HU0tpGEID6ZhXqm1XdXpuluVlrKGqF6C9DtvXnR/z7YEyQS7fX0B6dAlCpVEKlUsHKykprvlQqxcmTJ9u0Ly0txRdffIEdO3Y8cN03btyAp6cnrKysEBERgYSEBPj6+nbYXqFQQKFQaD7L5XId9oSIyHi1qNS4XCTXhN3Z21UorG5s087R2gKhvo4I9XPEMF8HDPF2gEyi/WtfpRbQ2KJCQ7OyNRQVKjS2KFGvUKGhuXV+Q7NKE5j3/vxpngqNzcq7y91tr1ChoUUFlbr1smqzUo1mpRrVDS0P3DcBMMwAtLW1RUREBNatW4f+/fvDzc0Nu3fvRnp6OgIDA9u037FjB2xtbTFz5sz7rjc8PBzbt29HcHAwiouL8eqrr2L06NHIzs7u8HluCQkJePXVV3Upn4jIKJXVNuHs7Wqcy2s9w7tQUANFO2d3QW62CPVzRKivI8L8HNG3j/UDHwkmNhPBRmIOG0n33nYSBAEKpVorOBu0QrQ1OBuafwraeoUKw/0cu7WO+9H5jfC5ublYuHAhjh8/DrFYjNDQUAQFBSErKwtXrlzRahsSEoLHHnsM7733nk5FVVdXw8/PD++88w4WLVrUbpv2zgB9fHxQU1PDZ4ESkdFqUalxpVh+93Jm6/27gqq2Z3cO1hYY5uOgOcMb4uPQ7SFmjORyOezt7TuVBTofrYCAAKSlpaG+vh5yuRweHh6YNWtWm3t8J06cwLVr17B3715dNwEHBwcEBQUhJyenwzYSiQQSiUTndRMRGZLyWsXdS5lVOHe7GhcKqzX35e4RiYBgN1sM83VEqK8DQv0c4e8s47tPf6Uu/3NBJpNBJpOhqqoKycnJ2LBhg9b3H330EcLCwjBkyBCd111XV4fc3FzMnTu3q+URERkcpUqNqyW1rYF39wwv705Dm3b2UgsM8717dufriCE+9rC1stBDxb2bzgGYnJwMQRAQHByMnJwcxMfHIyQkBHFxcZo2crkc+/btw9tvv93uOiZMmIAZM2Zg6dKlAIAXXngBU6dOhZ+fH4qKivDKK69ALBYjNja2i7tFRKR/lXUKzWXMs7db7901tmj3shSJgIdcbTRhF+rnAH9nG5iZ8eyup+kcgDU1NVi9ejUKCgrg5OSEmJgYrF+/HhYWP/3rZM+ePRAEocMAy83NRUVFheZzQUEBYmNjUVlZCRcXF4waNQqnT5+Gi8tv0xOIiEgXgiCgoVmFqoZmVDe0oKqhGXfqf/r5dmUDzuZV4XZl27M7Wyvzny5l+jpiqK8D7Hh2pxc6d4IxVLrc+CQiukelFlDd0IyqhhbNn63B9rN59S1aYVfd0IJmlfrBK8fPzu78WgMvwIVndz2pRzvBEBEZqsa7Z2U/D6uqhhZU1/8UZne0gq0Z8iZll7dnKTaDg7UFHK0tNX86yizgZmeFoT4OGObjCHtrnt0ZKgYgERkNpUqN8/nVSLtejtzyujZnZr8cG6cLWyvz1gCztoCD1p+toXZv3s/DztpSzJ6YRowBSEQGraSmCWnXy5B2vRwnblSg9gFnbOZmonbDykFm8YuAs4TT3WCzl1rAwkCfV0k9hwFIRAalWanGmVt3kHa9HGnXy3G1pFbrewdrC4x+yAXDfBzQx8ayTdjZSMx5VkadwgAkIr3Lv9OAY9fLkXatHKdyK9Dwswcyi0TAEG8HjA1ywdhgFwzxdoCYnUioGzAAieg319SiwukfKzVneT+W12t972xjiTFBLhgb5ILRD7nASWapp0qpN2MAElGPEwQBNyvqcexaa+Cd/rFSq8OK2EyEMF9HjA1uDb0BHnYcKkA9jgFIRD2iXqHEqdxKTQeW/DvaD3R2t7PCuLuBFxnoDHsphwvQb4sBSETdQhAEXCutRdrds7zMW3fQovrpORsWYhFG9nNqvZcX5IogNxt2ViG9YgASUZfVNLbgu5wKTeiVyJu0vvdxkmJckCvGBrkgIqBPm5exEukT/zYSUaep1QIuFck1lzXP5lVr3voNABJzM0QE9Ll7lueCfnxlDxkwBiAR3ded+macuNE6ROH4jXJU1DVrfR/gIsPYIFeMDXZBeD8nWFmI9VQpkW4YgETURv6dBhw8V4jUq2W4UFCNnz8yX2YpRmSgs+Ysz8fJWn+FEv0KDEAiAgDUKZT48kIx9p8tQMbNO1rfhbjbaoYoDPdzgqU5HxtGxo8BSGTCVGoBp3IrcCCrAEculaCppXVsnkgEPBrgjKlDPDA2yBXu9lZ6rpSo+zEAiUxQbnkdDmQV4OC5QhTX/NRz099Zhpgwb8wY5gVPB6keKyTqeQxAIhNR09CCzy4U4UBWAc7nV2vm21mZY+oQT8SEeWOYjwN7bZLJYAAS9WJKlRpp18tx4GwBvr5cpnmLudhMhLFBLogJ9caE/q7suUkmSec72bW1tVixYgX8/PwglUoRGRmJzMxMzfcikajd6a233rrvejdt2oS+ffvCysoK4eHhyMjI0H1viAgAcKVYjtc+v4xHElKxaMcZfHmxBM0qNULcbfH/TemP9NW/w8cLRmDKYA+GH5ksnc8AFy9ejOzsbCQmJsLT0xNJSUmIiorC5cuX4eXlheLiYq32X331FRYtWoSYmJgO17l3716sWrUKW7ZsQXh4ODZu3Ijo6Ghcu3YNrq6uuu8VkQmqqFPg0PnWS5yXi+Wa+X1klnh8qCdiQr0x0NOOlziJ7hIJws9H+NxfY2MjbG1tcejQIUyZMkUzPywsDJMnT8Zrr73WZpnp06ejtrYWqampHa43PDwcI0aMwPvvvw8AUKvV8PHxwfPPP48XX3yxU7XJ5XLY29ujpqYGdnZ2nd0lIqOmUKrw7dUy7M8qxLFrZVDefSqLhViECSFuiAnzxrhgF77tnEyGLlmg0xmgUqmESqWClZV2l2ipVIqTJ0+2aV9aWoovvvgCO3bs6HCdzc3NyMrKwurVqzXzzMzMEBUVhfT09A6XUygUUCgUms9yubzDtkS9iSAIuFBQgwNnC/DZD0WobmjRfDfE2x4xYd6YOtgTjnyHHtF96RSAtra2iIiIwLp169C/f3+4ublh9+7dSE9PR2BgYJv2O3bsgK2tLWbOnNnhOisqKqBSqeDm5qY1383NDVevXu1wuYSEBLz66qu6lE9k1EpqmnDwXCEOnC1ATlmdZr6bnQTTh3nhiVBvPORmq8cKiYyLzvcAExMTsXDhQnh5eUEsFiM0NBSxsbHIyspq0/bjjz/GnDlz2pwxdofVq1dj1apVms9yuRw+Pj7dvh0ifWpqUSH5UgkOnC3EyRvluPfcaYm5GaIHuiMmzBujAp0h5stjiXSmcwAGBAQgLS0N9fX1kMvl8PDwwKxZs+Dv76/V7sSJE7h27Rr27t173/U5OztDLBajtLRUa35paSnc3d07XE4ikUAikehaPpHBEwQBZ25X4UBWAb64UIxahVLz3Yi+jogJ9cbvB3vAzoovkCX6Nbo8DlAmk0Emk6GqqgrJycnYsGGD1vcfffQRwsLCMGTIkPuux9LSEmFhYUhNTcX06dMBtHaCSU1NxdKlS7taHhGA1ieebDhyFfJGJawtxZBaiiGzNG/9UyKGtaU5pBatP0stzSG728b6Zz/fay8xN+vRHpT5dxrwv7OF+N+5AtyubNDM93KQIibUCzNDvdHXWdZj2ycyNToHYHJyMgRBQHBwMHJychAfH4+QkBDExcVp2sjlcuzbtw9vv/12u+uYMGECZsyYoQm4VatWYf78+Rg+fDhGjhyJjRs3or6+XmudRLoqkzdh3kcZKKxu7Jb1mYnws/BsDU5rSzGsJeawthDDWnL3s6X53T87+vnunxIxxCIRvrlahgNnC3D6x58eQG1tKcbvH/ZATKg3wvs5wYyXOIm6nc4BWFNTg9WrV6OgoABOTk6IiYnB+vXrYWHx0+WYPXv2QBAExMbGtruO3NxcVFRUaD7PmjUL5eXlWLNmDUpKSjB06FAcOXKkTccYos6qUyixYFsmCqsb0c9ZhhVRD6GpRYWG5nuTEvUKFRqbVWhoUaFBodTM/3mbhmYVFMrWp6eoBaBWoWy9JFmreEAFuhOJgMiAPogJ9cakQe6wtuSDmoh6kk7jAA0ZxwHSPS0qNRZuz8SJGxVwtrHE/557FL59uv7OOqVKjcZfhKfm53vB2U6INjarUK8VqG2/EwSgn7MMMaFemBHqDS8+gJroV+mxcYBEhk4QBLx44CJO3KiA1EKMj+aP+FXhBwDmYjPYis1g282dTgRBgEKp7vF7i0TUPgYg9SrvpFzHgbMFEJuJ8MGcUAzxcdB3SR0SiUR8DieRHvH5SNRr7Pz+Nt77JgcAsH76IIwP4XNkiahjDEDqFVKvlOLlT7MBAMsmPITZI331XBERGToGIBm98/nVWLrrHNQC8Mfh3lgZ9ZC+SyIiI8AAJKN2q6IeC7dnorFFhbFBLlg/42F2KCGiTmEAktGqrFNg/rYM3KlvxiAvO3wwJ5Sv/SGiTuNvCzJKDc1KLNxxBrcrG+DtKMXHC0ZAJmGnZiLqPAYgGR2lSo3nd53DD/nVcLC2wI6FI+Fq2/1vHCGi3o0BSEZFEASs+ewSUq+WQWJuho/mD0eAi42+yyIiI8QAJKOy6dsc7Po+DyIR8K/ZwxDm56TvkojISDEAyWjszyrAP49eBwCsnToQkwZ1/L5IIqIHYQCSUTh+vRwvHrgAAPjTWH/Mj+yr34KIyOgxAMngZRfW4LmkLCjVAqYN9cTfo0P0XRIR9QIMQDJoBVUNiNueifpmFSL8+2DDE4P5clgi6hYMQDJY1Q3NmP9xBsprFQhxt8WH88IgMefbE4ioezAAySA1tajwzH/PILe8Hh72VtgWNwJ23fw+PiIybQxAMjhqtYCVe88j81YVbK3MsT1uJDzs+aZ0IupeOgdgbW0tVqxYAT8/P0ilUkRGRiIzM1OrzZUrV/D444/D3t4eMpkMI0aMQF5eXofr3L59O0QikdZkZcUne5giQRCw7ovL+Cq7BJZiM2ydOxzB7rb6LouIeiGdH564ePFiZGdnIzExEZ6enkhKSkJUVBQuX74MLy8v5ObmYtSoUVi0aBFeffVV2NnZ4dKlSw8MNDs7O1y7dk3zmU/0N00fnbyJbd/dAgD8849DEBHQR78FEVGvJRIEQehs48bGRtja2uLQoUOYMmWKZn5YWBgmT56M1157DbNnz4aFhQUSExM7XcT27duxYsUKVFdX61T8z8nlctjb26OmpgZ2dnZdXg/pz+EfivD87nMAgJd+H4JnxwTouSIiMja6ZIFOl0CVSiVUKlWbszmpVIqTJ09CrVbjiy++QFBQEKKjo+Hq6orw8HB8+umnD1x3XV0d/Pz84OPjg2nTpuHSpUv3ba9QKCCXy7UmMl7puZX46yc/AAAWRPbFM6P99VwREfV2OgWgra0tIiIisG7dOhQVFUGlUiEpKQnp6ekoLi5GWVkZ6urq8MYbb2DSpEk4evQoZsyYgZkzZyItLa3D9QYHB+Pjjz/GoUOHkJSUBLVajcjISBQUFHS4TEJCAuzt7TWTj4+PLrtCBuR6aS2eTTyDZpUakwa64+U/DOAlcCLqcTpdAgWA3NxcLFy4EMePH4dYLEZoaCiCgoKQlZWF1NRUeHl5ITY2Frt27dIs8/jjj0Mmk2H37t2d2kZLSwv69++P2NhYrFu3rt02CoUCCoVC81kul8PHx4eXQI1MSU0TZnzwHYprmjDczxFJi8NhZcGxfkTUNT12CRQAAgICkJaWhrq6OuTn5yMjIwMtLS3w9/eHs7MzzM3NMWDAAK1l+vfvf99eoL9kYWGBYcOGIScnp8M2EokEdnZ2WhMZF3lTCxZsy0BxTRMCXGT4z/zhDD8i+s10eRygTCaDh4cHqqqqkJycjGnTpsHS0hIjRozQ6s0JANevX4efn1+n161SqXDx4kV4eHh0tTwycM1KNf6cmIWrJbVwsZVge9xIOFhb6rssIjIhOg+DSE5OhiAICA4ORk5ODuLj4xESEoK4uDgAQHx8PGbNmoUxY8Zg/PjxOHLkCA4fPoxjx45p1jFv3jx4eXkhISEBAPCPf/wDjzzyCAIDA1FdXY233noLt2/fxuLFi7tnL8mgqNUC/rb/B5zKrYTMUoxtC0bAx8la32URkYnROQBramqwevVqFBQUwMnJCTExMVi/fj0sLFofUzVjxgxs2bIFCQkJWLZsGYKDg3HgwAGMGjVKs468vDyYmf108llVVYVnnnkGJSUlcHR0RFhYGE6dOtXmUir1Dm8dvYZPzxfB3EyEzU+HYZCXvb5LIiITpHMnGEPFcYDGITH9Fl4+1DrE5a0nBuPJ4ey9S0Tdp0c7wRB1VfKlEqz5rDX8/vpYEMOPiPSKAUi/iazbVVi2+xwEAYgd6YulvwvUd0lEZOIYgNTjfiyvw+IdmVAo1ZgQ4op10wZyoDsR6R0DkHpUWW0T5m/LQFVDC4b4OOC9p4bBXMy/dkSkf/xNRD2mXqHEou1nkH+nEX59rPHR/OGwttS54zERUY9gAFKPaFGpsWTXWVwsrIGTzBI74kbC2Uai77KIiDQYgNTtBEHA/x28iGPXymFlYYaP5g9HX2eZvssiItLCAKRu96/UG/jkTAHMRMD7saEY5uuo75KIiNpgAFK32puZh41f3wAArJs+CFED3PRcERFR+xiA1G2+vVaGlw5mAwCWjg/EnPDOPwCdiOi3xgCkbnGhoBpLdp6FSi1gZqgX/joxSN8lERHdFwOQfrVbFfVYuD0TDc0qjH7IGW/MHMyB7kRk8BiA9Kucz69GzOZTqKhrxgAPO3wwJxSW5vxrRUSGj6OSqctSLpfi+d1n0dSixkBPO2yLGwFbKwt9l0VE1CkMQOqSxPRbeOWzS1ALwNggF2yaEwobCf86EZHx4G8s0olaLeDN5Kv4MO1HAMDsET5YN30QLPh8TyIyMgxA6rSmFhVe2PcDPr9QDAB4YWIQlowPZIcXIjJKDEDqlOqGZjybmIWMm3dgbibChicGY2aot77LIiLqMp2vW9XW1mLFihXw8/ODVCpFZGQkMjMztdpcuXIFjz/+OOzt7SGTyTBixAjk5eXdd7379u1DSEgIrKys8PDDD+PLL7/UtTTqIfl3GhCz+RQybt6BrcQcOxaOZPgRkdHTOQAXL16MlJQUJCYm4uLFi5g4cSKioqJQWFgIAMjNzcWoUaMQEhKCY8eO4cKFC3j55ZdhZWXV4TpPnTqF2NhYLFq0COfOncP06dMxffp0ZGdnd33PqFtcLKjBjA9OIbe8Hh72Vtj3XAQeDXTWd1lERL+aSBAEobONGxsbYWtri0OHDmHKlCma+WFhYZg8eTJee+01zJ49GxYWFkhMTOx0EbNmzUJ9fT0+//xzzbxHHnkEQ4cOxZYtWzq1DrlcDnt7e9TU1MDOzq7T26aOfXO1FEt2nkNjiwoh7rbYHjcS7vYd/0OGiEjfdMkCnc4AlUolVCpVm7M5qVSKkydPQq1W44svvkBQUBCio6Ph6uqK8PBwfPrpp/ddb3p6OqKiorTmRUdHIz09vcNlFAoF5HK51kTdZ9f3eVi84wwaW1qf7rLvzxEMPyLqVXQKQFtbW0RERGDdunUoKiqCSqVCUlIS0tPTUVxcjLKyMtTV1eGNN97ApEmTcPToUcyYMQMzZ85EWlpah+stKSmBm5v2WwPc3NxQUlLS4TIJCQmwt7fXTD4+PrrsCnVArRaw4chVvHTwItQC8GSYNz5ewAHuRNT76HwPMDExEYIgwMvLCxKJBO+++y5iY2NhZmYGtVoNAJg2bRpWrlyJoUOH4sUXX8Qf/vCHTl/K7KzVq1ejpqZGM+Xn53fr+k2RQqnCyk/O44NjuQCAFVEPYcMTgznGj4h6JZ2HQQQEBCAtLQ319fWQy+Xw8PDArFmz4O/vD2dnZ5ibm2PAgAFay/Tv3x8nT57scJ3u7u4oLS3VmldaWgp3d/cOl5FIJJBIJLqWTx2oaWzBnxLP4PSPrcMcEmY+jCeH86yaiHqvLv/TXiaTwcPDA1VVVUhOTsa0adNgaWmJESNG4Nq1a1ptr1+/Dj+/jt8NFxERgdTUVK15KSkpiIiI6Gp5pIPC6kY8sfkUTv94BzYSc3y8YATDj4h6PZ3PAJOTkyEIAoKDg5GTk4P4+HiEhIQgLi4OABAfH49Zs2ZhzJgxGD9+PI4cOYLDhw/j2LFjmnXMmzcPXl5eSEhIAAAsX74cY8eOxdtvv40pU6Zgz549OHPmDLZu3do9e0kdyi6swcLtmSirVcDNToJtC0ZigCd70RJR76fzGWBNTQ2WLFmCkJAQzJs3D6NGjUJycjIsLFo7ScyYMQNbtmzBhg0b8PDDD+M///kPDhw4gFGjRmnWkZeXh+LiYs3nyMhI7Nq1C1u3bsWQIUOwf/9+fPrppxg0aFA37CJ15Ni1Msz6MB1ltQoEu9ni4F8eZfgRkcnQaRygIeM4QN3szczDSwezoVILeDSwDzY/HQY79vQkIiOnSxbwWaAmRhAE/L+U63j3mxwAwMxQL7wxczBfYktEJocBaEKalWq8eOAC/neu9bF1y34XiJWPBfFtDkRkkhiAJkLe1ILnkrLwXU4lxGYirJ8+CLNH+uq7LCIivWEAmoDimkbEbcvE1ZJayCzF2DQnFOOCXfVdFhGRXjEAe7krxXLEbctEibwJLrYSbFswAoO87PVdFhGR3jEAe7ETN8rxXNJZ1CmUeMjVBtviRsDb0VrfZRERGQQGYC+170w+Vv/vIpRqAY/4O+HDp4fD3prDHIiI7mEA9jKCIODd1Bz8v6+vAwCmDfXEhicGQ2Iu1nNlRESGhQHYi7So1Pi/gxfxyZkCAMBfxgXghYnBMDPjMAciol9iAPYStU0t+MvOszhxowJmImDd9EGYE97xA8iJiEwdA7AXKJU3YcG2TFwplkNqIcamOcPwuxC3By9IRGTCGIBG7lpJLeK2ZaCopgnONhJ8vGA4Bns76LssIiKDxwA0YqdyKvCnpCzUNikR4CLD9riR8HHiMAcios5gABqpg+cK8Lf9F9CiEjCyrxO2zguDg7WlvssiIjIaDEAjIwgCNn2bg38ebR3m8IfBHvjnk0NgZcFhDkREumAAGhGlSo2XD2Vjd0Y+AOBPY/3x9+gQDnMgIuoCBqCRqFcosWTXWRy7Vg4zEbD28YGYF9FX32URERktBqCRePnTbBy7Vg4rCzO8FxuKxwZwmAMR0a+h82vAa2trsWLFCvj5+UEqlSIyMhKZmZma7xcsWACRSKQ1TZo06b7rXLt2bZtlQkJCdN+bXqq8VoHDF4oAANsWjGT4ERF1A53PABcvXozs7GwkJibC09MTSUlJiIqKwuXLl+Hl5QUAmDRpErZt26ZZRiKRPHC9AwcOxNdff/1TYeY8Ob3nkzP5aFEJGObrgIiAPvouh4ioV9ApZRobG3HgwAEcOnQIY8aMAdB69nb48GFs3rwZr732GoDWwHN3d9etEHNznZcxBSq1gN0ZeQDAR5sREXUjnS6BKpVKqFQqWFlZac2XSqU4efKk5vOxY8fg6uqK4OBgPPfcc6isrHzgum/cuAFPT0/4+/tjzpw5yMvLu297hUIBuVyuNfVGx2+Uo6CqEfZSC/xhsIe+yyEi6jV0CkBbW1tERERg3bp1KCoqgkqlQlJSEtLT01FcXAyg9fLnf//7X6SmpuLNN99EWloaJk+eDJVK1eF6w8PDsX37dhw5cgSbN2/GzZs3MXr0aNTW1na4TEJCAuzt7TWTj4+PLrtiNHaevg0AeCLMm2P9iIi6kUgQBEGXBXJzc7Fw4UIcP34cYrEYoaGhCAoKQlZWFq5cudKm/Y8//oiAgAB8/fXXmDBhQqe2UV1dDT8/P7zzzjtYtGhRu20UCgUUCoXms1wuh4+PD2pqamBnZ6fLLhmswupGjH7zG6gFIPWvYxHgYqPvkoiIDJpcLoe9vX2nskDnXqABAQFIS0tDXV0d8vPzkZGRgZaWFvj7+7fb3t/fH87OzsjJyen0NhwcHBAUFHTfZSQSCezs7LSm3mZPRh7UAhAZ0IfhR0TUzXQOwHtkMhk8PDxQVVWF5ORkTJs2rd12BQUFqKyshIdH5+9f1dXVITc3V6dlepsWlRp7Mluf+MLOL0RE3U/nAExOTsaRI0dw8+ZNpKSkYPz48QgJCUFcXBzq6uoQHx+P06dP49atW0hNTcW0adMQGBiI6OhozTomTJiA999/X/P5hRdeQFpaGm7duoVTp05hxowZEIvFiI2N7Z69NEJfXy5Fea0CzjYSjvsjIuoBOg+2q6mpwerVq1FQUAAnJyfExMRg/fr1sLCwgFKpxIULF7Bjxw5UV1fD09MTEydOxLp167TGAubm5qKiokLzuaCgALGxsaisrISLiwtGjRqF06dPw8XFpXv20gglfd/a+WX2CB9Ymnf5RJ2IiDqgcycYQ6XLjU9D92N5HX73dhpEIuDE38bD25Hv+CMi6owe7QRDPW/X961jIH8X7MrwIyLqIQxAA9PUosL+swUAgDmP+Oq5GiKi3osBaGC+vFiM6oYWeDlIMTbIVd/lEBH1WgxAA5N098kvT4X7QswX3RIR9RgGoAG5XCTH2bxqmJuJ8ORwb32XQ0TUqzEADcjOu0Mfoge5w9XW6gGtiYjo12AAGog6hRKfnisEAMwJZ+cXIqKexgA0EIfOF6K+WQV/Fxki/PnSWyKinsYANACCICDp9E8vvRWJ2PmFiKinMQANwLn8alwplkNiboaYUC99l0NEZBIYgAbg3tCHPwz2hIO1pZ6rISIyDQxAPatuaMbnF4oBAE/zyS9ERL8ZBqCe7c8qQLNSjQEedhjq46DvcoiITAYDUI8EQdA8+PrpR9j5hYjot8QA1KP03Er8WFEPG4k5Hh/qqe9yiIhMCgNQj+699Hb6ME/YSHR+NzEREf0KDEA9KZM34eilUgCtY/+IiOi3xQDUk0/O5EOpFhDm54j+Hsb9BnsiImOkcwDW1tZixYoV8PPzg1QqRWRkJDIzMzXfL1iwACKRSGuaNGnSA9e7adMm9O3bF1ZWVggPD0dGRoaupRkNlVrA7ox8ABz6QESkLzoH4OLFi5GSkoLExERcvHgREydORFRUFAoLCzVtJk2ahOLiYs20e/fu+65z7969WLVqFV555RWcPXsWQ4YMQXR0NMrKynTfIyNw7FoZCqsb4WBtgcmDPPRdDhGRSdIpABsbG3HgwAFs2LABY8aMQWBgINauXYvAwEBs3rxZ004ikcDd3V0zOTo63ne977zzDp555hnExcVhwIAB2LJlC6ytrfHxxx93ba8M3L0nvzwZ5g0rC7GeqyEiMk06BaBSqYRKpYKVlfa76qRSKU6ePKn5fOzYMbi6uiI4OBjPPfccKisrO1xnc3MzsrKyEBUV9VNRZmaIiopCenq6LuUZhfw7DTh2vRwA8BQ7vxAR6Y1OAWhra4uIiAisW7cORUVFUKlUSEpKQnp6OoqLWx/nNWnSJPz3v/9Famoq3nzzTaSlpWHy5MlQqVTtrrOiogIqlQpubm5a893c3FBSUtJhLQqFAnK5XGsyBnsy8yAIwKhAZ/Rzlum7HCIik6Xz4LPExEQsXLgQXl5eEIvFCA0NRWxsLLKysgAAs2fP1rR9+OGHMXjwYAQEBODYsWOYMGFCtxWekJCAV199tdvW91toVqqxN5OdX4iIDIHOnWACAgKQlpaGuro65OfnIyMjAy0tLfD392+3vb+/P5ydnZGTk9Pu987OzhCLxSgtLdWaX1paCnd39w7rWL16NWpqajRTfn6+rrvymzt6uQQVdc1wtZVgQn+3By9AREQ9psvjAGUyGTw8PFBVVYXk5GRMmzat3XYFBQWorKyEh0f7vR0tLS0RFhaG1NRUzTy1Wo3U1FRERER0uH2JRAI7OzutydDd6/wye4QPLMQcgklEpE86/xZOTk7GkSNHcPPmTaSkpGD8+PEICQlBXFwc6urqEB8fj9OnT+PWrVtITU3FtGnTEBgYiOjoaM06JkyYgPfff1/zedWqVfj3v/+NHTt24MqVK3juuedQX1+PuLi47tlLA5BTVofTP96BmQiYPZKXP4mI9E3ne4A1NTVYvXo1CgoK4OTkhJiYGKxfvx4WFhZQKpW4cOECduzYgerqanh6emLixIlYt24dJBKJZh25ubmoqKjQfJ41axbKy8uxZs0alJSUYOjQoThy5EibjjHG7N5bH34X4gZPB6meqyEiIpEgCIK+i+gOcrkc9vb2qKmpMbjLoY3NKoS//jXkTUpsjxuBccGu+i6JiKhX0iULeCPqN/D5hSLIm5TwdpRizEMu+i6HiIjAAPxNJN29/PlUuC/MzPjSWyIiQ8AA7GHZhTX4Ib8aFmIR/jjcR9/lEBHRXQzAHrbz7tnfpEEecLaRPKA1ERH9VhiAPai2qQWHzre+JWNOOIc+EBEZEgZgD/r0XCEamlUIdLVBeD8nfZdDREQ/wwDsIYIgIOl06+XPOeG+EInY+YWIyJAwAHtI1u0qXCuthZWFGWaGeuu7HCIi+gUGYA+51/nl8SGesJda6LkaIiL6JQZgD7hT34wvLrS+H3EOX3pLRGSQGIA9YH9WPppVajzsZY8hPg76LoeIiNrBAOxmarWgufzJoQ9ERIaLAdjNvsutwO3KBthKzPH4UE99l0NERB1gAHaznXeHPswM9YK1pc5vmyIiot8IA7AbldQ0IeVKKQBgziPs/EJEZMgYgN1ob2Y+VGoBI/s6IcjNVt/lEBHRfTAAu4lSpcbujLudXx5h5xciIkPHAOwm31wtQ4m8CU4yS0wa5K7vcoiI6AF0DsDa2lqsWLECfn5+kEqliIyMRGZmZrtt//znP0MkEmHjxo33XefatWshEom0ppCQEF1L06t7Qx+eHO4NiblYz9UQEdGD6NxNcfHixcjOzkZiYiI8PT2RlJSEqKgoXL58GV5eXpp2Bw8exOnTp+Hp2bmhAAMHDsTXX3/9U2HmxtODMq+yAcdvlAMAnhrJy59ERMZApzPAxsZGHDhwABs2bMCYMWMQGBiItWvXIjAwEJs3b9a0KywsxPPPP4+dO3fCwqJzz8E0NzeHu7u7ZnJ2dtZtT/RoV0YeBAEYE+QCvz4yfZdDRESdoFMAKpVKqFQqWFlZac2XSqU4efIkAECtVmPu3LmIj4/HwIEDO73uGzduwNPTE/7+/pgzZw7y8vJ0KU1vFEoVPjmTD4BPfiEiMiY6BaCtrS0iIiKwbt06FBUVQaVSISkpCenp6Sgubn3485tvvglzc3MsW7as0+sNDw/H9u3bceTIEWzevBk3b97E6NGjUVtb2+EyCoUCcrlca9KHI9kluFPfDHc7K0wIcdVLDUREpDudO8EkJiZCEAR4eXlBIpHg3XffRWxsLMzMzJCVlYV//etf2L59u04vgJ08eTKefPJJDB48GNHR0fjyyy9RXV2NTz75pMNlEhISYG9vr5l8fHx03ZVuca/zy+yRPjAXs1MtEZGx0Pk3dkBAANLS0lBXV4f8/HxkZGSgpaUF/v7+OHHiBMrKyuDr6wtzc3OYm5vj9u3b+Otf/4q+fft2ehsODg4ICgpCTk5Oh21Wr16NmpoazZSfn6/rrvxq10trkXHzDsRmIswewcufRETGpMtdLWUyGWQyGaqqqpCcnIwNGzYgJiYGUVFRWu2io6Mxd+5cxMXFdXrddXV1yM3Nxdy5cztsI5FIIJFIulp+t9h19+wvqr8r3O2tHtCaiIgMic4BmJycDEEQEBwcjJycHMTHxyMkJARxcXGwsLBAnz59tNpbWFjA3d0dwcHBmnkTJkzAjBkzsHTpUgDACy+8gKlTp8LPzw9FRUV45ZVXIBaLERsb+yt3r+c0NCtxIKsAAF96S0RkjHQOwJqaGqxevRoFBQVwcnJCTEwM1q9f3+nhDgCQm5uLiooKzeeCggLExsaisrISLi4uGDVqFE6fPg0XFxddy/vNHP6hCLUKJfz6WGNUoPEM2SAiolYiQRAEfRfRHeRyOezt7VFTUwM7O7se397j75/EhYIarJ4cgj+NDejx7RER0YPpkgXsttgFFwqqcaGgBpZiMzwR5q3vcoiIqAsYgF1w76W3v3/YHX1s9NsRh4iIuoYBqKOaxhYc+qEQAF96S0RkzBiAOjp4tgBNLWoEudlguJ+jvsshIqIuYgDqQBAEzZNfnn7ET6en3RARkWFhAOog4+Yd3Cirg9RCjOnDvB68ABERGSwGoA7unf1NH+YJO6vOj3skIiLDwwDspIo6Bb7Kbn3jxVMj2fmFiMjYMQA7ad+ZArSoBAzxtsfD3vb6LoeIiH4lBmAnqNUCdmXcBsChD0REvQUDsBOO3yhH/p1G2FmZY+pgT32XQ0RE3YAB2An3Or/EhHlDainWczVERNQdGIAPUFTdiNQrpQCAOeF86S0RUW/BAHyAPZn5UAtAeD8nBLra6rscIiLqJgzA+2hRqbEn46cnvxARUe/BALyP1CulKKtVwNnGEtED3fVdDhERdSMG4H3c6/zyx+E+sDTnoSIi6k34W70DNyvqceJGBUQiIHYkO78QEfU2OgdgbW0tVqxYAT8/P0ilUkRGRiIzM7Pdtn/+858hEomwcePGB65306ZN6Nu3L6ysrBAeHo6MjAxdS+tWu+/e+xsb5AIfJ2u91kJERN1P5wBcvHgxUlJSkJiYiIsXL2LixImIiopCYWGhVruDBw/i9OnT8PR88MDxvXv3YtWqVXjllVdw9uxZDBkyBNHR0SgrK9O1vG7R1KLCvjP5AICnw9n5hYioN9IpABsbG3HgwAFs2LABY8aMQWBgINauXYvAwEBs3rxZ066wsBDPP/88du7cCQuLB7814Z133sEzzzyDuLg4DBgwAFu2bIG1tTU+/vhj3feoG3yVXYyqhhZ42lthfIirXmogIqKepVMAKpVKqFQqWFlZac2XSqU4efIkAECtVmPu3LmIj4/HwIEDH7jO5uZmZGVlISoq6qeizMwQFRWF9PR0XcrrNjtPt17+nD3SF2IzvvSWiKg30ikAbW1tERERgXXr1qGoqAgqlQpJSUlIT09HcXHrq4LefPNNmJubY9myZZ1aZ0VFBVQqFdzc3LTmu7m5oaSkpMPlFAoF5HK51tQdrpbIceZ2FcRmIswe4dMt6yQiIsOj8z3AxMRECIIALy8vSCQSvPvuu4iNjYWZmRmysrLwr3/9C9u3b4dI1LNnTgkJCbC3t9dMPj7dE1b3zv4mDnCDq53VA1oTEZGx0jkAAwICkJaWhrq6OuTn5yMjIwMtLS3w9/fHiRMnUFZWBl9fX5ibm8Pc3By3b9/GX//6V/Tt27fd9Tk7O0MsFqO0tFRrfmlpKdzdOx58vnr1atTU1Gim/Px8XXeljXqFEgfPtXbm4ZNfiIh6ty6PA5TJZPDw8EBVVRWSk5Mxbdo0zJ07FxcuXMD58+c1k6enJ+Lj45GcnNzueiwtLREWFobU1FTNPLVajdTUVERERHS4fYlEAjs7O63p1zp0vgh1CiX6OcsQ4d/nV6+PiIgMl7muCyQnJ0MQBAQHByMnJwfx8fEICQlBXFwcLCws0KePdnBYWFjA3d0dwcHBmnkTJkzAjBkzsHTpUgDAqlWrMH/+fAwfPhwjR47Exo0bUV9fj7i4uF+5e50nCAJ2ft/60tunRvrCjJ1fiIh6NZ0DsKamBqtXr0ZBQQGcnJwQExOD9evXd2q4wz25ubmoqKjQfJ41axbKy8uxZs0alJSUYOjQoThy5EibjjE9SaFUY6CnHQqqGvFEmPdvtl0iItIPkSAIgr6L6A5yuRz29vaoqan5VZdDFUoVJOZ86S0RkTHSJQv4LNBfYPgREZkGBiAREZkkBiAREZkkBiAREZkkBiAREZkkBiAREZkkBiAREZkknQfCG6p7wxm7660QRERkfO5lQGeGuPeaAKytrQWAbnsrBBERGa/a2lrY29vft02veRKMWq1GUVERbG1te/xVTPogl8vh4+OD/Pz8bnnwtynhsesaHreu4XHrmu46boIgoLa2Fp6enjAzu/9dvl5zBmhmZgZv797/DM/uevOFKeKx6xoet67hceua7jhuDzrzu4edYIiIyCQxAImIyCQxAI2ERCLBK6+8AolEou9SjA6PXdfwuHUNj1vX6OO49ZpOMERERLrgGSAREZkkBiAREZkkBiAREZkkBiAREZkkBqCBS0hIwIgRI2BrawtXV1dMnz4d165d03dZRueNN96ASCTCihUr9F2KwSssLMTTTz+NPn36QCqV4uGHH8aZM2f0XZbBU6lUePnll9GvXz9IpVIEBARg3bp1nXompSk5fvw4pk6dCk9PT4hEInz66ada3wuCgDVr1sDDwwNSqRRRUVG4ceNGj9TCADRwaWlpWLJkCU6fPo2UlBS0tLRg4sSJqK+v13dpRiMzMxMffvghBg8erO9SDF5VVRUeffRRWFhY4KuvvsLly5fx9ttvw9HRUd+lGbw333wTmzdvxvvvv48rV67gzTffxIYNG/Dee+/puzSDUl9fjyFDhmDTpk3tfr9hwwa8++672LJlC77//nvIZDJER0ejqamp+4sRyKiUlZUJAIS0tDR9l2IUamtrhYceekhISUkRxo4dKyxfvlzfJRm0v//978KoUaP0XYZRmjJlirBw4UKteTNnzhTmzJmjp4oMHwDh4MGDms9qtVpwd3cX3nrrLc286upqQSKRCLt37+727fMM0MjU1NQAAJycnPRciXFYsmQJpkyZgqioKH2XYhQ+++wzDB8+HE8++SRcXV0xbNgw/Pvf/9Z3WUYhMjISqampuH79OgDghx9+wMmTJzF58mQ9V2Y8bt68iZKSEq3/X+3t7REeHo709PRu316veRi2KVCr1VixYgUeffRRDBo0SN/lGLw9e/bg7NmzyMzM1HcpRuPHH3/E5s2bsWrVKrz00kvIzMzEsmXLYGlpifnz5+u7PIP24osvQi6XIyQkBGKxGCqVCuvXr8ecOXP0XZrRKCkpAQC4ublpzXdzc9N8150YgEZkyZIlyM7OxsmTJ/VdisHLz8/H8uXLkZKSAisrK32XYzTUajWGDx+O119/HQAwbNgwZGdnY8uWLQzAB/jkk0+wc+dO7Nq1CwMHDsT58+exYsUKeHp68tgZKF4CNRJLly7F559/jm+//dYkXvv0a2VlZaGsrAyhoaEwNzeHubk50tLS8O6778Lc3BwqlUrfJRokDw8PDBgwQGte//79kZeXp6eKjEd8fDxefPFFzJ49Gw8//DDmzp2LlStXIiEhQd+lGQ13d3cAQGlpqdb80tJSzXfdiQFo4ARBwNKlS3Hw4EF888036Nevn75LMgoTJkzAxYsXcf78ec00fPhwzJkzB+fPn4dYLNZ3iQbp0UcfbTPM5vr16/Dz89NTRcajoaGhzQtYxWIx1Gq1nioyPv369YO7uztSU1M18+RyOb7//ntERER0+/Z4CdTALVmyBLt27cKhQ4dga2uruQ5ub28PqVSq5+oMl62tbZv7pDKZDH369OH90/tYuXIlIiMj8frrr+OPf/wjMjIysHXrVmzdulXfpRm8qVOnYv369fD19cXAgQNx7tw5vPPOO1i4cKG+SzModXV1yMnJ0Xy+efMmzp8/DycnJ/j6+mLFihV47bXX8NBDD6Ffv354+eWX4enpienTp3d/Md3er5S6FYB2p23btum7NKPDYRCdc/jwYWHQoEGCRCIRQkJChK1bt+q7JKMgl8uF5cuXC76+voKVlZXg7+8v/N///Z+gUCj0XZpB+fbbb9v9nTZ//nxBEFqHQrz88suCm5ubIJFIhAkTJgjXrl3rkVr4OiQiIjJJvAdIREQmiQFIREQmiQFIREQmiQFIREQmiQFIREQmiQFIREQmiQFIREQmiQFIREQmiQFIREQmiQFIREQmiQFIREQmiQFIREQm6f8H+LUnjWQ+/ZMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(np.arange(1,epochs+1), lossv)\n",
        "plt.title('validation loss')\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(np.arange(1,epochs+1), accv)\n",
        "plt.title('validation accuracy');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, save the trained model and load it later for inference."
      ],
      "metadata": {
        "id": "e8b2cbpqizay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model_save_path = \"mnist_mlp_mixer.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hi03bAri4XK",
        "outputId": "7d37a6bf-5a12-44a1-847b-b96927887a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to mnist_mlp_mixer.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And add the following code to load the saved model for inference:"
      ],
      "metadata": {
        "id": "1Q4NyW9Ei-Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "model_load_path = \"mnist_mlp_mixer.pth\"\n",
        "loaded_model = MLPMixer(input_size=(28, 28), patch_size=(7, 7), dim=64, img_channel=1, layers=8, num_classes=10).to(device)\n",
        "loaded_model.load_state_dict(torch.load(model_load_path))\n",
        "loaded_model.eval()\n",
        "print(f\"Model loaded from {model_load_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBxltZFoi7Qk",
        "outputId": "3ed62369-8b12-4476-8da5-a1a380d8da8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from mnist_mlp_mixer.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can use the loaded_model for inference. For example, let's classify a single image from the validation dataset:"
      ],
      "metadata": {
        "id": "eeDCmiCAjEuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference on a single image from the validation dataset\n",
        "data, target = validation_dataset[0]\n",
        "data = data.unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = loaded_model(data)\n",
        "    pred = output.data.max(1)[1].item()\n",
        "\n",
        "print(f\"Predicted class: {pred}, True class: {target}\")\n",
        "\n",
        "data, target = validation_dataset[0]\n",
        "img = data.squeeze(0).numpy()\n",
        "\n",
        "plt.imshow(img, cmap=\"gray_r\")\n",
        "plt.title(f\"Image True Class: {target}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "0zyN5BNBjJ4v",
        "outputId": "e4aced4c-6a3f-4e75-cfc3-0661ab157c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 7, True class: 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9gpz9XY0qPW"
      },
      "source": [
        "## Model tuning\n",
        "\n",
        "Next I have modified the MLP-Mixer model and tried to improve the classification accuracy. We can do this through experimentation with the effects of different parameters.  To experiment with different parameters and find the best ones, we can perform a grid search over the parameter space. This is done for different patch size, dimension, and number of layers. As shown below, the code will train the model with different parameter combinations and keep track of the best parameters that yield the highest accuracy on the validation dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuhYFJF-0qPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f196c4-fd81-482f-f667-50211f3b7a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with parameters: patch_size=(4, 4), dim=64, layers=6\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.284711\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.242515\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.494908\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.230486\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.200305\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.208254\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.167976\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.135267\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.279295\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.092097\n",
            "\n",
            "Validation set: Average loss: 0.1286, Accuracy: 9598/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.094684\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.035357\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.122508\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.194203\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.166140\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.073434\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.201203\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.087897\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.029269\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.033774\n",
            "\n",
            "Validation set: Average loss: 0.1029, Accuracy: 9667/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.195262\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.013613\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.106626\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.147697\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.036742\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.081786\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.080400\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.318017\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.010632\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.054710\n",
            "\n",
            "Validation set: Average loss: 0.0770, Accuracy: 9761/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.155194\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.125635\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.079619\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.132955\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.026623\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.160954\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.041671\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.031417\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.019662\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.124188\n",
            "\n",
            "Validation set: Average loss: 0.0773, Accuracy: 9747/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.022287\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.180861\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.152000\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.066082\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.016674\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.106271\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.012674\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.193783\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.098252\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.065454\n",
            "\n",
            "Validation set: Average loss: 0.0722, Accuracy: 9775/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(4, 4), dim=64, layers=8\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.411772\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.426850\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.103258\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.312282\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.317925\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.236324\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.318879\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.097227\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.132982\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.048740\n",
            "\n",
            "Validation set: Average loss: 0.1494, Accuracy: 9515/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.112685\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.177902\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.048925\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.172212\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.077311\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.300784\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.122791\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.077982\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.134262\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.061229\n",
            "\n",
            "Validation set: Average loss: 0.1037, Accuracy: 9673/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.070736\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.031784\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.104263\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.004852\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.020077\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.057166\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.197690\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.133102\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.113282\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.191675\n",
            "\n",
            "Validation set: Average loss: 0.0859, Accuracy: 9732/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.037839\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.144068\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.212433\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.281670\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.069365\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.211790\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.121803\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.028897\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.055508\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.018069\n",
            "\n",
            "Validation set: Average loss: 0.0697, Accuracy: 9797/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.108807\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.004085\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.062184\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.028825\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.020335\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.016552\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.041032\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.030092\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.192885\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.007037\n",
            "\n",
            "Validation set: Average loss: 0.0736, Accuracy: 9786/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(4, 4), dim=64, layers=10\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.327076\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.555053\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.177047\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.169759\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.170621\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.057682\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.226037\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.153416\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.099046\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.232378\n",
            "\n",
            "Validation set: Average loss: 0.1428, Accuracy: 9562/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.059824\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.257822\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.079520\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.138614\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.135125\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.053138\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.582676\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.046267\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.014902\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.165063\n",
            "\n",
            "Validation set: Average loss: 0.1060, Accuracy: 9680/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.229276\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.494868\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.310746\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.121722\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.309854\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.026404\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.028228\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.158100\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.119728\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.031666\n",
            "\n",
            "Validation set: Average loss: 0.0996, Accuracy: 9690/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.010958\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.034251\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.061922\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.085794\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.063105\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.022670\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.113566\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.171459\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.045557\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.102245\n",
            "\n",
            "Validation set: Average loss: 0.0850, Accuracy: 9743/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001782\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.071541\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.042698\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.059890\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.037345\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.119308\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.130240\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.136441\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.035848\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.112228\n",
            "\n",
            "Validation set: Average loss: 0.0619, Accuracy: 9799/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(4, 4), dim=128, layers=6\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.368696\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.221704\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.401122\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.256510\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.116654\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.153942\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.086339\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.107816\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.415174\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.039361\n",
            "\n",
            "Validation set: Average loss: 0.1327, Accuracy: 9576/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.052990\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.066046\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.188334\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.038454\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.007092\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.087815\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.261286\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.094971\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.153756\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.101436\n",
            "\n",
            "Validation set: Average loss: 0.0914, Accuracy: 9724/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.031452\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.128844\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.042945\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.165645\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.051452\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.122377\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.006359\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.045738\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.243971\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.035515\n",
            "\n",
            "Validation set: Average loss: 0.0688, Accuracy: 9782/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.101271\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.132162\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.075639\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.112337\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.094214\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.163278\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.341681\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.063620\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.156886\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.140812\n",
            "\n",
            "Validation set: Average loss: 0.0613, Accuracy: 9811/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.007554\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.018180\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.058468\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.006225\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.156830\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.008237\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.042691\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.006565\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.018436\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.041520\n",
            "\n",
            "Validation set: Average loss: 0.0648, Accuracy: 9806/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(4, 4), dim=128, layers=8\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.358643\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.389661\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.217838\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.421591\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.114162\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.073888\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.306323\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.389492\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.117721\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.160658\n",
            "\n",
            "Validation set: Average loss: 0.1193, Accuracy: 9642/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.106143\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.282335\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.178996\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.197463\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.215626\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.023722\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.182796\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.131787\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.038176\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.047689\n",
            "\n",
            "Validation set: Average loss: 0.0954, Accuracy: 9703/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.243458\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.023911\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.026764\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.137104\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.148644\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.210925\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.102423\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.020451\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.031814\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.009360\n",
            "\n",
            "Validation set: Average loss: 0.0813, Accuracy: 9746/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.042671\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.009494\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.049201\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.222681\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.002041\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.011440\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.066269\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.066280\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.025928\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.033322\n",
            "\n",
            "Validation set: Average loss: 0.0839, Accuracy: 9754/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.229528\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.007191\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.070951\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.006004\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.131145\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.004211\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.003388\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.013206\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.025589\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.073920\n",
            "\n",
            "Validation set: Average loss: 0.0714, Accuracy: 9781/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(4, 4), dim=128, layers=10\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304464\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.660979\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.484362\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.358574\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.244056\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.121758\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.092221\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.162563\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.154892\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.080100\n",
            "\n",
            "Validation set: Average loss: 0.1228, Accuracy: 9639/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.040559\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.163521\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.037611\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.140549\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.275313\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.079010\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.032311\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.035001\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.061445\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.170463\n",
            "\n",
            "Validation set: Average loss: 0.1385, Accuracy: 9589/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.043861\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.005167\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.290309\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.223023\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.015586\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.037481\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.018966\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.061614\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.046011\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.240702\n",
            "\n",
            "Validation set: Average loss: 0.0900, Accuracy: 9731/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.036106\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.012801\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.149997\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.160063\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.015130\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.020282\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.270306\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.183277\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.013064\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.078389\n",
            "\n",
            "Validation set: Average loss: 0.0740, Accuracy: 9762/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.011413\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.011097\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.169392\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.056174\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.004911\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.275244\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.044545\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.007389\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.129775\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.005854\n",
            "\n",
            "Validation set: Average loss: 0.0828, Accuracy: 9750/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(4, 4), dim=256, layers=6\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.343935\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.756558\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.234004\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.162454\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.120771\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.213908\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.049262\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.078176\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.124431\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.315781\n",
            "\n",
            "Validation set: Average loss: 0.1129, Accuracy: 9659/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.029199\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.065172\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.167220\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.002796\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.048706\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.044420\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.018026\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.077247\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.044797\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.107802\n",
            "\n",
            "Validation set: Average loss: 0.1211, Accuracy: 9624/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.017557\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.129963\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.083221\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.089393\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.003678\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.145827\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.194587\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.026659\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.012692\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.023733\n",
            "\n",
            "Validation set: Average loss: 0.0891, Accuracy: 9703/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.058985\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.012491\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.035468\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.006814\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.177420\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.106940\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.278861\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.011538\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.027320\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.009915\n",
            "\n",
            "Validation set: Average loss: 0.0814, Accuracy: 9761/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.004319\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.003064\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.039617\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.007831\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.004346\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.018851\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.014874\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.148061\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.219797\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.111696\n",
            "\n",
            "Validation set: Average loss: 0.0696, Accuracy: 9781/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(4, 4), dim=256, layers=8\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304775\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.369780\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.192197\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.080283\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.227805\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.246946\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.308049\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.043427\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.193489\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.032403\n",
            "\n",
            "Validation set: Average loss: 0.1925, Accuracy: 9479/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.048142\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.222953\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.132384\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.119172\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.189185\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.165427\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.431028\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.291916\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.114946\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.122485\n",
            "\n",
            "Validation set: Average loss: 0.0970, Accuracy: 9719/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.240989\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.135099\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.458484\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.090251\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.008396\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.107503\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.006217\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.535464\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.085656\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.265338\n",
            "\n",
            "Validation set: Average loss: 0.0814, Accuracy: 9750/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.005514\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.157589\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.097173\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.018133\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.167556\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.010016\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.011422\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.339682\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.002646\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.058053\n",
            "\n",
            "Validation set: Average loss: 0.0635, Accuracy: 9789/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.011017\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.236996\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.114807\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.014453\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.316527\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.072139\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.053295\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.047917\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.187461\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.000668\n",
            "\n",
            "Validation set: Average loss: 0.0674, Accuracy: 9809/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(4, 4), dim=256, layers=10\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.361701\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.964839\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.337323\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.375716\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.175326\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.240143\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.405330\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.224664\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.354355\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.056309\n",
            "\n",
            "Validation set: Average loss: 0.1312, Accuracy: 9587/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.144009\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.261376\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.341123\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.016675\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.013589\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.331868\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.070958\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.258327\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.180755\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.337420\n",
            "\n",
            "Validation set: Average loss: 0.0951, Accuracy: 9703/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.087674\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.075322\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.059452\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.004818\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.008754\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.044306\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.041687\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.127838\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.087392\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.010800\n",
            "\n",
            "Validation set: Average loss: 0.0703, Accuracy: 9772/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.006790\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.022397\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.004930\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.356163\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.154611\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.005526\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.009953\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.036370\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.011643\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.001785\n",
            "\n",
            "Validation set: Average loss: 0.1154, Accuracy: 9645/10000 (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.035599\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.034748\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.084261\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.197480\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.461140\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.067890\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.113216\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.002075\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.029183\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.015128\n",
            "\n",
            "Validation set: Average loss: 0.0686, Accuracy: 9794/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(7, 7), dim=64, layers=6\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.332245\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.444321\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.371383\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.492041\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.112738\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.242573\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.287481\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.248362\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.197630\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.065709\n",
            "\n",
            "Validation set: Average loss: 0.1361, Accuracy: 9581/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.067720\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.331844\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.148022\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.464877\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.055471\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.156990\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.086225\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.041994\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.149794\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.513726\n",
            "\n",
            "Validation set: Average loss: 0.1187, Accuracy: 9626/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.158029\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.147657\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.411840\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.038654\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.026686\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.069582\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.014522\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.104263\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.100620\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.062897\n",
            "\n",
            "Validation set: Average loss: 0.0928, Accuracy: 9706/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.050752\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.062814\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.092068\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.043414\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.005293\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.056229\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.032442\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.089534\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.395138\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.070419\n",
            "\n",
            "Validation set: Average loss: 0.0948, Accuracy: 9693/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.037218\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.126297\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.034191\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.007841\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.015049\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.064053\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.076356\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.067579\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.085483\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.159361\n",
            "\n",
            "Validation set: Average loss: 0.0793, Accuracy: 9740/10000 (97%)\n",
            "\n",
            "Training with parameters: patch_size=(7, 7), dim=64, layers=8\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.331000\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.410621\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.519435\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.259808\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.174742\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.437703\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.405723\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.042205\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.173592\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.236464\n",
            "\n",
            "Validation set: Average loss: 0.1242, Accuracy: 9630/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.354085\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.244952\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.008398\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.271665\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.233315\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.100031\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.102006\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.059985\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.124900\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.282632\n",
            "\n",
            "Validation set: Average loss: 0.0970, Accuracy: 9685/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.181634\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.045923\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.070324\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.256886\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.113640\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.081698\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.016915\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.014245\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.058928\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.123686\n",
            "\n",
            "Validation set: Average loss: 0.0932, Accuracy: 9721/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.217982\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.005223\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.027438\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.122888\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.122262\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.023656\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.114015\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.010481\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.048330\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.190528\n",
            "\n",
            "Validation set: Average loss: 0.0791, Accuracy: 9746/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.169683\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.044202\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.042479\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.071170\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.288352\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.018492\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.019759\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.043342\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.051436\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.201181\n",
            "\n",
            "Validation set: Average loss: 0.0681, Accuracy: 9782/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(7, 7), dim=64, layers=10\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.327790\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.658503\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.197762\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.120589\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.222707\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.121723\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.277754\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.162767\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.325470\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.103140\n",
            "\n",
            "Validation set: Average loss: 0.1350, Accuracy: 9572/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.244584\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.230598\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.027817\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.066420\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.045972\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.063567\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.054988\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.070713\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.195625\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.193752\n",
            "\n",
            "Validation set: Average loss: 0.0961, Accuracy: 9698/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.097561\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.006374\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.010279\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.172690\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.047717\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.102719\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.183466\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.033676\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.191451\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.056204\n",
            "\n",
            "Validation set: Average loss: 0.0880, Accuracy: 9731/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.021438\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.048480\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.005567\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.159639\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.012046\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.272688\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.209630\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.170276\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.081484\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.036988\n",
            "\n",
            "Validation set: Average loss: 0.0800, Accuracy: 9753/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.060904\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.037967\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.030649\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.046670\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.042402\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.037680\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.018388\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.534643\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.044647\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.019252\n",
            "\n",
            "Validation set: Average loss: 0.0621, Accuracy: 9811/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(7, 7), dim=128, layers=6\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.325964\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.438335\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.469396\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.481407\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.220458\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.076897\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.124858\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.101300\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.037464\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.048134\n",
            "\n",
            "Validation set: Average loss: 0.1153, Accuracy: 9647/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.119896\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.040204\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.013439\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.059309\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.232731\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.092187\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.064562\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.050298\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.102847\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.032273\n",
            "\n",
            "Validation set: Average loss: 0.1026, Accuracy: 9686/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.211080\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.111919\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.058510\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.205888\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.156068\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.455678\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.031628\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.579138\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.043573\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.092482\n",
            "\n",
            "Validation set: Average loss: 0.0816, Accuracy: 9741/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.004400\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.057337\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.183227\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.082475\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.034097\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.022297\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.012025\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.004323\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.010876\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.020767\n",
            "\n",
            "Validation set: Average loss: 0.0819, Accuracy: 9752/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.061539\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.008196\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.122727\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.036028\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.013655\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.059725\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.047646\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.379094\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.100821\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.085838\n",
            "\n",
            "Validation set: Average loss: 0.0657, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(7, 7), dim=128, layers=8\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.269325\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.305340\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.170351\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.415899\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.209325\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.155627\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.338649\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.400356\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.105035\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.214773\n",
            "\n",
            "Validation set: Average loss: 0.1137, Accuracy: 9652/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.135253\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.145531\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.365451\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.058058\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.171884\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.014057\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.020159\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.059760\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.128607\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.072016\n",
            "\n",
            "Validation set: Average loss: 0.1029, Accuracy: 9673/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.025822\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.047728\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.015415\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.125537\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.089118\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.072845\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.287171\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.181161\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.061164\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.055361\n",
            "\n",
            "Validation set: Average loss: 0.0834, Accuracy: 9744/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.034579\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.025750\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.302875\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.008240\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.040512\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.149997\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.140440\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.005901\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.197967\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.010018\n",
            "\n",
            "Validation set: Average loss: 0.0697, Accuracy: 9777/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.095729\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.031369\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.139485\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.163407\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.013027\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.011451\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.046231\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.005405\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.005665\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.044504\n",
            "\n",
            "Validation set: Average loss: 0.0745, Accuracy: 9777/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(7, 7), dim=128, layers=10\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.402741\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.335723\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.215455\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.220974\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.143769\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.081672\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.219137\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.110501\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.018186\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.042278\n",
            "\n",
            "Validation set: Average loss: 0.1126, Accuracy: 9656/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.093321\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.120384\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.395068\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.023427\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.065773\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.063500\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.005362\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.267638\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.052827\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.100137\n",
            "\n",
            "Validation set: Average loss: 0.0998, Accuracy: 9687/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.189827\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.011110\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.040658\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.021036\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.113860\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.028293\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.299800\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.063134\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.036831\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.019164\n",
            "\n",
            "Validation set: Average loss: 0.0779, Accuracy: 9768/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.120199\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.151337\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.060690\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.115067\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.283505\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.007239\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.009584\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.012766\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.164212\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.032919\n",
            "\n",
            "Validation set: Average loss: 0.0791, Accuracy: 9759/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.030801\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.083601\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.059731\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.063945\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.010260\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.275285\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.005030\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.286508\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.296760\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.019021\n",
            "\n",
            "Validation set: Average loss: 0.0720, Accuracy: 9785/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(7, 7), dim=256, layers=6\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.299605\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.451897\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.381286\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.476638\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.091292\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.341838\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.179530\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.101294\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.207848\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.066381\n",
            "\n",
            "Validation set: Average loss: 0.1038, Accuracy: 9665/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.050011\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.070073\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.089645\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.178752\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.431099\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.028389\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.009144\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.137339\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.069213\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.007731\n",
            "\n",
            "Validation set: Average loss: 0.0996, Accuracy: 9715/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.088670\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.014460\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.185895\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.067046\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.020891\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.179567\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.133781\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.106344\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.385727\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.167778\n",
            "\n",
            "Validation set: Average loss: 0.0830, Accuracy: 9739/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.028829\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.002263\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.003977\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.076905\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.020121\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.226888\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.004699\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.005331\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.079629\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.003527\n",
            "\n",
            "Validation set: Average loss: 0.0795, Accuracy: 9775/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.019441\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.059202\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.008640\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.011630\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.009897\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.120904\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.045429\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.016830\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.013504\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.193338\n",
            "\n",
            "Validation set: Average loss: 0.0697, Accuracy: 9800/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(7, 7), dim=256, layers=8\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.319354\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.601178\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.328363\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.109557\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.119511\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.213803\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.290868\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.084870\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.061029\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.172534\n",
            "\n",
            "Validation set: Average loss: 0.1327, Accuracy: 9610/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.190008\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.040491\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.060439\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.173846\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.095589\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.133035\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.069263\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.235585\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.021532\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.086659\n",
            "\n",
            "Validation set: Average loss: 0.1125, Accuracy: 9642/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.073277\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.033351\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.003709\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.196305\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.018428\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.057560\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.042478\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.172992\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.084955\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.057089\n",
            "\n",
            "Validation set: Average loss: 0.0776, Accuracy: 9764/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.017633\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.147948\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.005180\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.267240\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.078013\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.312727\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.084893\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.011068\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.134435\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.054649\n",
            "\n",
            "Validation set: Average loss: 0.0742, Accuracy: 9789/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.047191\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.015806\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.002527\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.006427\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.036070\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.046860\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.107526\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.121116\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.002826\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.034552\n",
            "\n",
            "Validation set: Average loss: 0.0752, Accuracy: 9790/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(7, 7), dim=256, layers=10\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.365400\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.378603\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.135419\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.206278\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.061172\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.263885\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.056653\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.331655\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.188050\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.162133\n",
            "\n",
            "Validation set: Average loss: 0.1306, Accuracy: 9587/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.056285\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.128524\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.126817\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.525833\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.005040\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.015813\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.025861\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.076608\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.084994\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.041734\n",
            "\n",
            "Validation set: Average loss: 0.1352, Accuracy: 9578/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.018148\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.019841\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.011669\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.011645\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.053680\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.201770\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.054092\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.514012\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.029186\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.003752\n",
            "\n",
            "Validation set: Average loss: 0.0911, Accuracy: 9738/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.012332\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.008044\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.082085\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.006871\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.011387\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.017650\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.014273\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.003301\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.074958\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.138355\n",
            "\n",
            "Validation set: Average loss: 0.0663, Accuracy: 9790/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.004970\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.130958\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.016153\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.016824\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.009766\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.140523\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.012339\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.053562\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.008813\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.017129\n",
            "\n",
            "Validation set: Average loss: 0.0770, Accuracy: 9799/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(14, 14), dim=64, layers=6\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.344530\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.125636\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.373925\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.146046\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.173129\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.230882\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.058310\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.035737\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.057180\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.170485\n",
            "\n",
            "Validation set: Average loss: 0.1219, Accuracy: 9630/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.149530\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.007775\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.029709\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.177989\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.095948\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.186328\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.071745\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.017436\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.048299\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.094348\n",
            "\n",
            "Validation set: Average loss: 0.1001, Accuracy: 9692/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.030148\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.021846\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.085257\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.014800\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.297326\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.064073\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.010622\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.009451\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.113101\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.094978\n",
            "\n",
            "Validation set: Average loss: 0.0769, Accuracy: 9762/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.014843\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.014629\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.015856\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.096274\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.011434\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.017265\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.027989\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.036635\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.072961\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.046621\n",
            "\n",
            "Validation set: Average loss: 0.0787, Accuracy: 9761/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.010237\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.012126\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.116648\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.037999\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.124082\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.140579\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.015593\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.118635\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.171435\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.005218\n",
            "\n",
            "Validation set: Average loss: 0.0798, Accuracy: 9767/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(14, 14), dim=64, layers=8\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.427438\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.059300\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.357582\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.110268\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.134572\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.027650\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.676295\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.159875\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.099449\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.097511\n",
            "\n",
            "Validation set: Average loss: 0.1119, Accuracy: 9654/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.193086\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.024990\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.172491\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.043438\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.350262\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.137912\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.006457\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.237508\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.055032\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.130563\n",
            "\n",
            "Validation set: Average loss: 0.0964, Accuracy: 9700/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.034154\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.108206\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.048051\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.124316\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.011353\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.191434\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.009231\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.205886\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.086369\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.060658\n",
            "\n",
            "Validation set: Average loss: 0.0921, Accuracy: 9718/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.047010\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.012604\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.119493\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.045903\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.009648\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.011678\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.044283\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.004379\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.009487\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.126387\n",
            "\n",
            "Validation set: Average loss: 0.0849, Accuracy: 9748/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001346\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.019909\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.018185\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.003549\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.039276\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.026621\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.010821\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.105070\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.024274\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.160037\n",
            "\n",
            "Validation set: Average loss: 0.0714, Accuracy: 9791/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(14, 14), dim=64, layers=10\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.361741\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.296276\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.240182\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.094443\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.087422\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.195527\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.030411\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.048329\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.159036\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.083415\n",
            "\n",
            "Validation set: Average loss: 0.1285, Accuracy: 9592/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.039616\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.155282\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.329996\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.129927\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.102654\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.297161\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.033097\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.112021\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.355560\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.214004\n",
            "\n",
            "Validation set: Average loss: 0.0957, Accuracy: 9707/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.032496\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.171389\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.138517\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.052609\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.020241\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.075378\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.045587\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.009241\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.284940\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.019428\n",
            "\n",
            "Validation set: Average loss: 0.0883, Accuracy: 9712/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.074649\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.040356\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.003965\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.047346\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.008855\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.068813\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.043834\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.036719\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.005906\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.011169\n",
            "\n",
            "Validation set: Average loss: 0.0697, Accuracy: 9785/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.005921\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.023948\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.014366\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.027629\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.006094\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.004926\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.062846\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.107749\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.011753\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.018441\n",
            "\n",
            "Validation set: Average loss: 0.0662, Accuracy: 9796/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(14, 14), dim=128, layers=6\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303907\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.204514\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.289506\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.084011\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.270170\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.199198\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.265216\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.248728\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.232190\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.151212\n",
            "\n",
            "Validation set: Average loss: 0.1339, Accuracy: 9580/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.174531\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.069035\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.192193\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.108061\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.107501\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.234389\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.086676\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.081720\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.053721\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.043849\n",
            "\n",
            "Validation set: Average loss: 0.0991, Accuracy: 9713/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.065442\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.255675\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.034621\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.044323\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.055669\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.120796\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.073482\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.280670\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.006114\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.441995\n",
            "\n",
            "Validation set: Average loss: 0.0757, Accuracy: 9769/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.055250\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.051259\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.016455\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.035258\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.001750\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.059226\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.171630\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.005793\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.004847\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.159046\n",
            "\n",
            "Validation set: Average loss: 0.0770, Accuracy: 9769/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.011862\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.009092\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.004159\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.010138\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.144415\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.013488\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.007706\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000666\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.084551\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.036304\n",
            "\n",
            "Validation set: Average loss: 0.0802, Accuracy: 9739/10000 (97%)\n",
            "\n",
            "Training with parameters: patch_size=(14, 14), dim=128, layers=8\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.450622\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.398733\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.175536\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.431761\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.171271\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.066178\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.326806\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.119129\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.062866\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.103943\n",
            "\n",
            "Validation set: Average loss: 0.0966, Accuracy: 9710/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.072038\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.150642\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.240153\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.052388\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.123888\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.082775\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.029685\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.084320\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.087256\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.041238\n",
            "\n",
            "Validation set: Average loss: 0.0804, Accuracy: 9740/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.108894\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.001195\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.009734\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.031548\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.011577\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.014886\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.024953\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.003193\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.010773\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.091622\n",
            "\n",
            "Validation set: Average loss: 0.0824, Accuracy: 9753/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.100463\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.083621\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.370810\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.030885\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.144120\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.003381\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.032809\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.041645\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.126499\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.005251\n",
            "\n",
            "Validation set: Average loss: 0.0695, Accuracy: 9787/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.023247\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.008665\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000719\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.118938\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.026348\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.034526\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.015069\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.002425\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.259044\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.063305\n",
            "\n",
            "Validation set: Average loss: 0.0650, Accuracy: 9787/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(14, 14), dim=128, layers=10\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.314472\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.234221\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.312634\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.033924\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.061922\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.019113\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.039678\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.051334\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.063045\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.018283\n",
            "\n",
            "Validation set: Average loss: 0.1078, Accuracy: 9649/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.143036\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.020295\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.031034\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.051411\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.111964\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.013041\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.234643\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.044856\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.225614\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.027365\n",
            "\n",
            "Validation set: Average loss: 0.0710, Accuracy: 9786/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.038176\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.015341\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.322746\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.001303\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.135701\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.092405\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.192681\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.052908\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.009267\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.004068\n",
            "\n",
            "Validation set: Average loss: 0.0755, Accuracy: 9775/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.040161\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.000746\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.005409\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.002072\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.002573\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.119894\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.128451\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.138155\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.027174\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.110917\n",
            "\n",
            "Validation set: Average loss: 0.0664, Accuracy: 9791/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.015073\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.110471\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.050306\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.000483\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.121801\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.078850\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.488421\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.026513\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.223168\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.011512\n",
            "\n",
            "Validation set: Average loss: 0.0666, Accuracy: 9812/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(14, 14), dim=256, layers=6\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.379550\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.295436\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.087917\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.203162\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.077833\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.051070\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.098138\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.276657\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.052488\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.202446\n",
            "\n",
            "Validation set: Average loss: 0.0986, Accuracy: 9673/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.101279\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.181501\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.036678\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.136747\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.142374\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.012797\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.046409\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.049568\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.108470\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.106017\n",
            "\n",
            "Validation set: Average loss: 0.0937, Accuracy: 9705/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.012340\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.007324\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.007430\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.007068\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.048021\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.020607\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.006120\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.053626\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.034142\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.296410\n",
            "\n",
            "Validation set: Average loss: 0.0745, Accuracy: 9753/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.068886\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.003056\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.119087\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.216615\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.017750\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.086683\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.009624\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.005707\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.123801\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.143320\n",
            "\n",
            "Validation set: Average loss: 0.0779, Accuracy: 9753/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.014673\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.054837\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.034288\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.001579\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.024390\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.016002\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.024585\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.137955\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.008469\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.007492\n",
            "\n",
            "Validation set: Average loss: 0.0732, Accuracy: 9768/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(14, 14), dim=256, layers=8\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.403696\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.287279\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.189340\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.169758\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.222182\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.089013\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.027949\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.065255\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.283243\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.032780\n",
            "\n",
            "Validation set: Average loss: 0.1029, Accuracy: 9658/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.159264\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.061958\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.015895\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.167454\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.046702\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.003746\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.219132\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.075731\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.093741\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.117488\n",
            "\n",
            "Validation set: Average loss: 0.0836, Accuracy: 9729/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.003643\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.038501\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.276907\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.081872\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.051313\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.232910\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.051472\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.005067\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.073868\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.160328\n",
            "\n",
            "Validation set: Average loss: 0.0735, Accuracy: 9761/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.102765\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.007937\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.028788\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.023182\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.003071\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.178759\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.003722\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.204124\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.033261\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.017294\n",
            "\n",
            "Validation set: Average loss: 0.0801, Accuracy: 9769/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.007893\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.007208\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.008491\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.000385\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.021270\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.018979\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.003994\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.179593\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.000554\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.114867\n",
            "\n",
            "Validation set: Average loss: 0.0750, Accuracy: 9801/10000 (98%)\n",
            "\n",
            "Training with parameters: patch_size=(14, 14), dim=256, layers=10\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.217082\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.301074\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.155619\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.064635\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.059945\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.294507\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.038433\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.110714\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.105732\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.318178\n",
            "\n",
            "Validation set: Average loss: 0.1087, Accuracy: 9663/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.267517\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.037058\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.027250\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.000620\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.117168\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.055708\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.179728\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.250903\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.181761\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.023970\n",
            "\n",
            "Validation set: Average loss: 0.0784, Accuracy: 9751/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.027916\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.003861\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.092887\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.001493\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.050708\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.017613\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.125455\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.042164\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000971\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.042343\n",
            "\n",
            "Validation set: Average loss: 0.0798, Accuracy: 9765/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.003947\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.002569\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.011731\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.005381\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.014373\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.044659\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.041530\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.168169\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.042393\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.111246\n",
            "\n",
            "Validation set: Average loss: 0.0786, Accuracy: 9810/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.000246\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000642\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000590\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.101036\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.035241\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.002189\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.012652\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000863\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.039004\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.001750\n",
            "\n",
            "Validation set: Average loss: 0.0766, Accuracy: 9791/10000 (98%)\n",
            "\n",
            "Best parameters: patch_size=(14, 14), dim=128, layers=10 with accuracy 98.12000274658203%\n"
          ]
        }
      ],
      "source": [
        "from itertools import product\n",
        "\n",
        "# Define the parameter space\n",
        "patch_sizes = [(4, 4), (7, 7), (14, 14)]\n",
        "dims = [64, 128, 256]\n",
        "layer_counts = [6, 8, 10]\n",
        "epochs = 5\n",
        "\n",
        "# Iterate over all combinations of parameters\n",
        "best_accuracy = 0\n",
        "best_params = None\n",
        "for patch_size, dim, layers in product(patch_sizes, dims, layer_counts):\n",
        "    print(f\"Training with parameters: patch_size={patch_size}, dim={dim}, layers={layers}\")\n",
        "\n",
        "    # Instantiate the model with the current parameters\n",
        "    model = MLPMixer(input_size=(28, 28), patch_size=patch_size, dim=dim, img_channel=1, layers=layers, num_classes=10).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model for 'epochs' epochs\n",
        "    lossv, accv = [], []\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(epoch)\n",
        "        validate(lossv, accv)\n",
        "\n",
        "    # Store the parameters if the accuracy is better than the best seen so far\n",
        "    final_accuracy = accv[-1]\n",
        "    if final_accuracy > best_accuracy:\n",
        "        best_accuracy = final_accuracy\n",
        "        best_params = (patch_size, dim, layers)\n",
        "\n",
        "print(f\"Best parameters: patch_size={best_params[0]}, dim={best_params[1]}, layers={best_params[2]} with accuracy {best_accuracy}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the hyperparameter search, it is found that the best parameters for the MLP-Mixer model on the MNIST dataset are:\n",
        "\n",
        "\n",
        "\n",
        "*   Patch size: (14, 14)\n",
        "*   Dimension: 128\n",
        "*   Number of layers: 10\n",
        "\n",
        "These parameters yielded an accuracy of 98.12% on the validation dataset.\n",
        "\n",
        "Now, a MLP-Mixer model is created and trained with these best parameters to obtain the optimal MLP-Mixer model for the MNIST dataset. "
      ],
      "metadata": {
        "id": "Ekj4ueQy-3yH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_patch_size = (14, 14)\n",
        "best_dim = 128\n",
        "best_layers = 10\n",
        "best_epochs = 10\n",
        "\n",
        "model = MLPMixer(input_size=(28, 28), patch_size=best_patch_size, dim=best_dim, img_channel=1, layers=best_layers, num_classes=10).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "lossv, accv = [], []\n",
        "for epoch in range(1, best_epochs + 1):\n",
        "    train(epoch)\n",
        "    validate(lossv, accv)\n",
        "\n",
        "# Save the trained model\n",
        "model_save_path = \"mnist_mlp_mixer_best.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIXr4CaA-3IW",
        "outputId": "b5f76d50-8c2b-46a6-cab7-19bd0a089e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.252705\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.130107\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.063943\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.180521\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.110671\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.085505\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.080979\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.059793\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.203266\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.038903\n",
            "\n",
            "Validation set: Average loss: 0.0973, Accuracy: 9693/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.037683\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.007420\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.109491\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.028394\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.225667\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.019602\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.070830\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.153599\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.077980\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.005700\n",
            "\n",
            "Validation set: Average loss: 0.0779, Accuracy: 9773/10000 (98%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.013777\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.111353\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.003959\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.194171\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.104673\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.015247\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.101333\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.118801\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000302\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.489032\n",
            "\n",
            "Validation set: Average loss: 0.0698, Accuracy: 9782/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.009401\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.022174\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.079132\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.100037\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.020380\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.020164\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.035562\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.000677\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.008226\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.118366\n",
            "\n",
            "Validation set: Average loss: 0.0686, Accuracy: 9784/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.008812\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.002280\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.056979\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.007413\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.070435\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.187295\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.037163\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.070863\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.259917\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.018307\n",
            "\n",
            "Validation set: Average loss: 0.0689, Accuracy: 9805/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.005845\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.035608\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.156577\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.005765\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.115910\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.030194\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.204362\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.021700\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.005032\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.003735\n",
            "\n",
            "Validation set: Average loss: 0.0664, Accuracy: 9818/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.067320\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.004704\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.013712\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.003567\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000685\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.075878\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.118134\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.006757\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.040018\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.007961\n",
            "\n",
            "Validation set: Average loss: 0.0730, Accuracy: 9813/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000610\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.011574\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.010555\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.000024\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.036966\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.036811\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.048805\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.127876\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.016196\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.000969\n",
            "\n",
            "Validation set: Average loss: 0.0682, Accuracy: 9791/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.006677\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.061410\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.002833\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000231\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.004063\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.124522\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.182587\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.190976\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.052420\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.137215\n",
            "\n",
            "Validation set: Average loss: 0.0891, Accuracy: 9779/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.073073\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.022450\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.082576\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.000042\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.093697\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.000489\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.002208\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.004090\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000643\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.021458\n",
            "\n",
            "Validation set: Average loss: 0.0811, Accuracy: 9779/10000 (98%)\n",
            "\n",
            "Model saved to mnist_mlp_mixer_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, the best MLP_Mixer with optimal parameters is saved to mnist_mlp_mixer_best.pth."
      ],
      "metadata": {
        "id": "I-VXRvaLRmfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison of the MLP-Mixer model with other baselines\n"
      ],
      "metadata": {
        "id": "zMTPT5MjCg0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the original model is compared with other baselines. For this a simple MLP and a convolutional neural network (CNN) is trained for comparison with the MLP-Mixer. Finally validation accuracies are used for comparison."
      ],
      "metadata": {
        "id": "nZy6QGrTCzri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First , new train and validate functions are added to accept the model and optimizer as arguments to compare with other baseline models."
      ],
      "metadata": {
        "id": "ykCXOa7kFKpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_baseline(epoch, model, optimizer, log_interval=200):\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Loop over each batch from the training set\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Copy data to GPU if needed\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Zero gradient buffers\n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        # Pass data through the network\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
        "\n",
        "def validate_baseline(loss_vector, accuracy_vector, model):\n",
        "    model.eval()\n",
        "    val_loss, correct = 0, 0\n",
        "    for data, target in validation_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        val_loss += criterion(output, target).data.item()\n",
        "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "\n",
        "    val_loss /= len(validation_loader)\n",
        "    loss_vector.append(val_loss)\n",
        "\n",
        "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
        "    accuracy_vector.append(accuracy)\n",
        "    \n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        val_loss, correct, len(validation_loader.dataset), accuracy))\n"
      ],
      "metadata": {
        "id": "R7HCmNz1FBIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports at the beginning of your code\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "CN4ep97vUzIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define number of epochs to train model \n",
        "epochs = 10\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.fc1 = nn.Linear(64 * 14 * 14, 128)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Instantiate the models\n",
        "mlp_model = MLP(28 * 28, 256, 10).to(device)\n",
        "cnn_model = CNN(10).to(device)\n",
        "\n",
        "# Train and evaluate the MLP model\n",
        "mlp_optimizer = torch.optim.SGD(mlp_model.parameters(), lr=0.01, momentum=0.5)\n",
        "mlp_scheduler = StepLR(mlp_optimizer, step_size=1, gamma=0.7)\n",
        "mlp_lossv, mlp_accv = [], []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_baseline(epoch, model=mlp_model, optimizer=mlp_optimizer)\n",
        "    validate_baseline(mlp_lossv, mlp_accv, model=mlp_model)\n",
        "    mlp_scheduler.step()\n",
        "\n",
        "# Train and evaluate the CNN model\n",
        "cnn_optimizer = torch.optim.SGD(cnn_model.parameters(), lr=0.01, momentum=0.5)\n",
        "cnn_scheduler = StepLR(cnn_optimizer, step_size=1, gamma=0.7)\n",
        "cnn_lossv, cnn_accv = [], []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_baseline(epoch, model=cnn_model, optimizer=cnn_optimizer)\n",
        "    validate_baseline(cnn_lossv, cnn_accv, model=cnn_model)\n",
        "    cnn_scheduler.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nosyeVv8DOFq",
        "outputId": "996ff740-01ac-487a-a587-65ae8766c8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.307098\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.298877\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.766726\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.471317\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.369042\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.437639\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.570218\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.410138\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.288348\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.066706\n",
            "\n",
            "Validation set: Average loss: 0.3240, Accuracy: 9103/10000 (91%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.412428\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.306439\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.580191\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.364450\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.520485\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.201974\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.128958\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.241457\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.120013\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.606784\n",
            "\n",
            "Validation set: Average loss: 0.2735, Accuracy: 9212/10000 (92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.521025\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.156488\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.303533\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.710899\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.322852\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.195824\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.386511\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.091148\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.324510\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.189554\n",
            "\n",
            "Validation set: Average loss: 0.2530, Accuracy: 9271/10000 (93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.329219\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.339000\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.218425\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.180866\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.093536\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.183762\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.181082\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.110455\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.241797\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.158777\n",
            "\n",
            "Validation set: Average loss: 0.2417, Accuracy: 9314/10000 (93%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.090124\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.185897\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.246802\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.179462\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.283810\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.115218\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.061206\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.289665\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.104290\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.220967\n",
            "\n",
            "Validation set: Average loss: 0.2315, Accuracy: 9339/10000 (93%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.231224\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.119913\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.068315\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.179138\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.171244\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.121964\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.073890\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.374060\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.167059\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.357422\n",
            "\n",
            "Validation set: Average loss: 0.2258, Accuracy: 9357/10000 (94%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.232121\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.075858\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.327253\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.116725\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.116085\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.224440\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.408811\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.102837\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.088406\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.158274\n",
            "\n",
            "Validation set: Average loss: 0.2224, Accuracy: 9371/10000 (94%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.108536\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.445389\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.058656\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.068000\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.239432\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.272603\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.209961\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.121904\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.176707\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.149132\n",
            "\n",
            "Validation set: Average loss: 0.2196, Accuracy: 9376/10000 (94%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.109278\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.165735\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.376548\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.263514\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.291404\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.128597\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.274229\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.213782\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.237302\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.537252\n",
            "\n",
            "Validation set: Average loss: 0.2177, Accuracy: 9382/10000 (94%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.200222\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.104336\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.160296\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.240389\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.108513\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.269906\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.127896\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.218566\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.294284\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.207527\n",
            "\n",
            "Validation set: Average loss: 0.2164, Accuracy: 9383/10000 (94%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.321167\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.729030\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.492564\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.282097\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.326173\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.200673\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.351389\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.441366\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.504296\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.144703\n",
            "\n",
            "Validation set: Average loss: 0.1765, Accuracy: 9480/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.141591\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.091648\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.468304\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.746290\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.117347\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.348684\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.430519\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.514950\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.180399\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.280969\n",
            "\n",
            "Validation set: Average loss: 0.1357, Accuracy: 9592/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.223456\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.141108\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.097953\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.066027\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.101536\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.623056\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.163111\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.527243\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.113590\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.085695\n",
            "\n",
            "Validation set: Average loss: 0.1097, Accuracy: 9672/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.132372\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.112337\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.156218\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.130991\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.161653\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.146474\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.151969\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.058486\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.091426\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.225259\n",
            "\n",
            "Validation set: Average loss: 0.0956, Accuracy: 9705/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.078300\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.289872\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.149718\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.085466\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.098964\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.068692\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.163145\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.123120\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.133761\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.270801\n",
            "\n",
            "Validation set: Average loss: 0.0853, Accuracy: 9730/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.126204\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.132190\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.198997\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.024156\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.035685\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.208994\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.121211\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.155113\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.205929\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.377633\n",
            "\n",
            "Validation set: Average loss: 0.0799, Accuracy: 9748/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.129612\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.178349\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.151516\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.057995\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.021806\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.160738\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.050533\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.030564\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.094092\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.079816\n",
            "\n",
            "Validation set: Average loss: 0.0765, Accuracy: 9757/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.097690\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.044242\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.083678\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.263098\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.116017\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.160599\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.061499\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.097728\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.091956\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.113693\n",
            "\n",
            "Validation set: Average loss: 0.0740, Accuracy: 9766/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.080628\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.113127\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.032819\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.207410\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.146784\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.110059\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.044840\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.028388\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.062346\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.033582\n",
            "\n",
            "Validation set: Average loss: 0.0721, Accuracy: 9769/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.122179\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.029017\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.037142\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.106813\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.035068\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.185379\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.369792\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.159074\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.104798\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.040843\n",
            "\n",
            "Validation set: Average loss: 0.0710, Accuracy: 9775/10000 (98%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the performance of the models\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(np.arange(1, epochs + 1), lossv, label=\"MLP-Mixer\")\n",
        "plt.plot(np.arange(1, epochs + 1), mlp_lossv, label=\"MLP\")\n",
        "plt.plot(np.arange(1, epochs + 1), cnn_lossv, label=\"CNN\")\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(np.arange(1, epochs + 1), accv, label=\"MLP-Mixer\")\n",
        "plt.plot(np.arange(1, epochs + 1), mlp_accv, label=\"MLP\")\n",
        "plt.plot(np.arange(1, epochs + 1), cnn_accv, label=\"CNN\")\n",
        "plt.title(\"Validation Accuracy\")\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "32Jyul40FeVE",
        "outputId": "78c5778b-3952-463d-91a6-0f81e46339ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0852f127f0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb8AAAEpCAYAAAADLCwsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMTElEQVR4nO3deVxU9f7H8dcwAzPAsCMgioKm5r5L7laUmreurS6UWzevV83MFrVFbTG3Fn+m161cKrdcsrq3a3opTY3Q9Jr7moobICj7MjBzfn8cGBhBZRAcls/z8TiPmTlz5pzPYPHm+z3f8z0aRVEUhBBCiBrEydEFCCGEEHebhJ8QQogaR8JPCCFEjSPhJ4QQosaR8BNCCFHjSPgJIYSocST8hBBC1DgSfkIIIWocCT8hhBA1joSfEKV07tw5NBoNK1assK6bNm0aGo2mVJ/XaDRMmzatXGvq1asXvXr1Ktd9ClETSPiJaumxxx7Dzc2NtLS0m24TGRmJi4sLSUlJd7Ey+x09epRp06Zx7tw5R5ditX37djQaDRs2bHB0KUKUiYSfqJYiIyPJysrim2++KfH9zMxMvv32W/r06YOfn1+Zj/PWW2+RlZVV5s+XxtGjR3nnnXdKDL+tW7eydevWCj2+ENWRhJ+olh577DE8PDxYvXp1ie9/++23ZGRkEBkZeUfH0el0GAyGO9rHnXBxccHFxcVhxxeiqpLwE9WSq6srTzzxBFFRUSQkJBR7f/Xq1Xh4ePDYY49x7do1Xn31VVq2bInRaMTT05O+ffvyxx9/3PY4JZ3zy8nJ4eWXX6ZWrVrWY1y8eLHYZ8+fP8/o0aNp0qQJrq6u+Pn58fTTT9u08FasWMHTTz8NwP33349Go0Gj0bB9+3ag5HN+CQkJPP/88wQGBmIwGGjdujUrV6602abg/OWHH37IkiVLaNiwIXq9no4dO7J3797bfu/S+vPPP3n66afx9fXFzc2N++67j3//+9/Ftvv0009p3rw5bm5u+Pj40KFDB5s/XNLS0hg/fjyhoaHo9XoCAgJ46KGH2L9/f7nVKmoWnaMLEKKiREZGsnLlSr7++mvGjh1rXX/t2jV+/PFHBg0ahKurK0eOHGHz5s08/fTThIWFER8fz+LFi+nZsydHjx4lODjYruP+7W9/46uvvmLw4MF06dKFn376iX79+hXbbu/evfz6668MHDiQunXrcu7cORYuXEivXr04evQobm5u9OjRg3HjxjFv3jzeeOMNmjZtCmB9vFFWVha9evXi9OnTjB07lrCwMNavX8+wYcNITk7mpZdestl+9erVpKWl8fe//x2NRsPs2bN54okn+PPPP3F2drbre98oPj6eLl26kJmZybhx4/Dz82PlypU89thjbNiwgccffxyApUuXMm7cOJ566ileeuklsrOzOXjwIDExMQwePBiAUaNGsWHDBsaOHUuzZs1ISkpi165dHDt2jHbt2t1RnaKGUoSopvLy8pTatWsrnTt3tlm/aNEiBVB+/PFHRVEUJTs7WzGbzTbbnD17VtHr9cq7775rsw5Qli9fbl03depUpej/RgcOHFAAZfTo0Tb7Gzx4sAIoU6dOta7LzMwsVnN0dLQCKF988YV13fr16xVA+fnnn4tt37NnT6Vnz57W13PnzlUA5auvvrKuM5lMSufOnRWj0aikpqbafBc/Pz/l2rVr1m2//fZbBVC+//77Yscq6ueff1YAZf369TfdZvz48Qqg7Ny507ouLS1NCQsLU0JDQ60/87/+9a9K8+bNb3k8Ly8vZcyYMbfcRgh7SLenqLa0Wi0DBw4kOjrapitx9erVBAYG8uCDDwKg1+txclL/VzCbzSQlJWE0GmnSpInd3Wo//PADAOPGjbNZP378+GLburq6Wp/n5uaSlJTEPffcg7e3d5m783744QeCgoIYNGiQdZ2zszPjxo0jPT2dHTt22Gw/YMAAfHx8rK+7d+8OqN2Vd+qHH36gU6dOdOvWzbrOaDQycuRIzp07x9GjRwHw9vbm4sWLt+xu9fb2JiYmhsuXL99xXUKAnPMT1VzBgJaC80cXL15k586dDBw4EK1WC4DFYuGTTz6hUaNG6PV6/P39qVWrFgcPHiQlJcWu450/fx4nJycaNmxos75JkybFts3KymLKlCmEhITYHDc5Odnu4xY9fqNGjaxhXqCgm/T8+fM26+vVq2fzuiAIr1+/Xqbj31hLSd/7xlomTpyI0WikU6dONGrUiDFjxrB7926bz8yePZvDhw8TEhJCp06dmDZtWrkEtKi5JPxEtda+fXvuvfde1qxZA8CaNWtQFMVmlOcHH3zAhAkT6NGjB1999RU//vgj27Zto3nz5lgslgqr7cUXX2T69Ok888wzfP3112zdupVt27bh5+dXocctquAPgBspinJXjg9qGJ44cYK1a9fSrVs3Nm7cSLdu3Zg6dap1m2eeeYY///yTTz/9lODgYObMmUPz5s35z3/+c9fqFNWLDHgR1V5kZCRvv/02Bw8eZPXq1TRq1IiOHTta39+wYQP3338/n3/+uc3nkpOT8ff3t+tY9evXx2KxcObMGZtWz4kTJ4ptu2HDBoYOHcpHH31kXZednU1ycrLNdqWdQabg+AcPHsRisdi0/o4fP259/26pX79+id+7pFrc3d0ZMGAAAwYMwGQy8cQTTzB9+nQmT55svZSkdu3ajB49mtGjR5OQkEC7du2YPn06ffv2vTtfSFQr0vIT1V5BK2/KlCkcOHCg2LV9Wq22WEtn/fr1XLp0ye5jFfwinjdvns36uXPnFtu2pON++umnmM1mm3Xu7u4AxUKxJI888ghxcXGsW7fOui4vL49PP/0Uo9FIz549S/M1ysUjjzzCnj17iI6Otq7LyMhgyZIlhIaG0qxZM4BiM+y4uLjQrFkzFEUhNzcXs9lcrBs4ICCA4OBgcnJyKv6LiGpJWn6i2gsLC6NLly58++23AMXC7y9/+Qvvvvsuw4cPp0uXLhw6dIhVq1bRoEEDu4/Vpk0bBg0axD//+U9SUlLo0qULUVFRnD59uti2f/nLX/jyyy/x8vKiWbNmREdH89///rfYjDNt2rRBq9Uya9YsUlJS0Ov1PPDAAwQEBBTb58iRI1m8eDHDhg1j3759hIaGsmHDBnbv3s3cuXPx8PCw+zvdysaNG60tuaKGDh3KpEmTWLNmDX379mXcuHH4+vqycuVKzp49y8aNG60t04cffpigoCC6du1KYGAgx44dY/78+fTr1w8PDw+Sk5OpW7cuTz31FK1bt8ZoNPLf//6XvXv32rSahbCLQ8eaCnGXLFiwQAGUTp06FXsvOztbeeWVV5TatWsrrq6uSteuXZXo6OhilxGU5lIHRVGUrKwsZdy4cYqfn5/i7u6uPProo8qFCxeKXepw/fp1Zfjw4Yq/v79iNBqV3r17K8ePH1fq16+vDB061GafS5cuVRo0aKBotVqbyx5urFFRFCU+Pt66XxcXF6Vly5Y2NRf9LnPmzCn287ixzpIUXOpws6Xg8oYzZ84oTz31lOLt7a0YDAalU6dOyr/+9S+bfS1evFjp0aOH4ufnp+j1eqVhw4bKa6+9pqSkpCiKoig5OTnKa6+9prRu3Vrx8PBQ3N3dldatWyv//Oc/b1mjELeiUZS7eGZbCCGEqATknJ8QQogaR8JPCCFEjSPhJ4QQosaR8BNCCFHjSPgJIYSocST8hBBC1DjV4iJ3i8XC5cuX8fDwsGsqKCGEENWLoiikpaURHBxcbIL3oqpF+F2+fJmQkBBHlyGEEKKSuHDhAnXr1r3p+9Ui/AqmbLpw4QKenp4OrkYIIYSjpKamEhISctup/KpF+BV0dXp6ekr4CSGEuO0pMBnwIoQQosaR8BNCCFHjSPgJIYSocarFOT8hhCiJ2WwmNzfX0WWIcuTs7IxWq73j/Uj4CSGqHUVRiIuLIzk52dGliArg7e1NUFDQHV3XLeEnhKh2CoIvICAANzc3mfyimlAUhczMTBISEgCoXbt2mfcl4VdU3GG4fg6a/sXRlQghyshsNluDz8/Pz9HliHLm6uoKQEJCAgEBAWXuApUBLwWSzsCKfrB+GJzc6uhqhBBlVHCOz83NzcGViIpS8G97J+dzJfwK+IRCwwfAkgtfPwdndzq6IiHEHZCuzuqrPP5tJfwKOGnhiSXQuA/kZcOagXDxd0dXJYQQogJI+BWldYanV0JYDzClw1dPQNwhR1clhBCVkkajYfPmzY4uo0wk/G7kbICBa6BuJ8hOgS/6Q+IpR1clhKgBhg0bhkajYdSoUcXeGzNmDBqNhmHDhlm37d+//033FRoaikajQaPR4O7uTrt27Vi/fv0tj1/wmbVr1xZ7r3nz5mg0GlasWGFdd+XKFfr27Vuq71bZSPiVRG+EyPUQ1BIyE+GLv8L1846uSghRA4SEhLB27VqysrKs67Kzs1m9ejX16tWza1/vvvsuV65c4X//+x8dO3ZkwIAB/Prrr7c9/vLly23W/fbbb8TFxeHu7m6zPigoCL1eb1dN9jCZTBW2bwm/m3H1huc2g38TSL0EXzwGqVccXZUQoppr164dISEhbNq0ybpu06ZN1KtXj7Zt29q1Lw8PD4KCgmjcuDELFizA1dWV77///pafiYyMZMeOHVy4cMG6btmyZURGRqLT2V4dV7Tb84svvsBoNHLqVGFP2ejRo7n33nvJzMwE4PDhw/Tt2xej0UhgYCDPPfcciYmJ1u179erF2LFjGT9+PP7+/vTu3duu72sPCb9bcfeHIZvBu756/d8Xf4WMxNt9SghRySiKQqYpzyGLoih21ztixAib1teyZcsYPnz4Hf0MdDodzs7Ot21NBQYG0rt3b1auXAlAZmYm69atY8SIEbf83JAhQ3jkkUeIjIwkLy+Pf//733z22WesWrUKNzc3kpOTeeCBB2jbti2///47W7ZsIT4+nmeeecZmPytXrsTFxYXdu3ezaNGiO/rOtyIXud+OZzAM/Q6W9YXEE/Dl4zD0e7VlKISoErJyzTSb8qNDjn303d64udj3q/bZZ59l8uTJnD+vnm7ZvXs3a9euZfv27WWqwWQy8dFHH5GSksIDDzxw2+1HjBjBK6+8wptvvsmGDRto2LAhbdq0ue3nFi9eTKtWrRg3bhybNm1i2rRptG/fHoD58+fTtm1bPvjgA+v2y5YtIyQkhJMnT9K4cWMAGjVqxOzZs8v0Pe0hLb/S8AmFId+Cmz/EHYTVz0BOuqOrEkJUU7Vq1aJfv36sWLGC5cuX069fP/z9/e3ez8SJEzEajbi5uTFr1ixmzpxJv379+OCDDzAajdYlNjbW5nP9+vUjPT2dX375hWXLlt221VfAx8eHzz//nIULF9KwYUMmTZpkfe+PP/7g559/tjnuvffeC8CZM2es2xWEZUWTll9p1WqsdoGu6AcXYmDtIBi8Xh0dKoSo1FydtRx9t+LOH93u2GUxYsQIxo4dC8CCBQvKtI/XXnuNYcOGWc+xFVwcPmrUKJvuxuDgYJvP6XQ6nnvuOaZOnUpMTAzffPNNqY/5yy+/oNVquXLlChkZGXh4eACQnp7Oo48+yqxZs4p9pugcnTcOqqkoEn72CGoJkRvVc39nf1GnQhvwpXp9oBCi0tJoNHZ3PTpanz59MJlMaDSaMg/88Pf355577im23tfXF19f31t+dsSIEXz44YcMGDAAHx+fUh3v119/ZdasWXz//fdMnDiRsWPHWs8dtmvXjo0bNxIaGlps4IwjSLenvUI6wuB1oDPAyf/AppFgMTu6KiFENaPVajl27BhHjx696eTNKSkpHDhwwGYpOkrzTjRt2pTExMRilz3cTFpaGs899xzjxo2jb9++rFq1inXr1rFhwwZAvU7x2rVrDBo0iL1793LmzBl+/PFHhg8fjtl893+HSviVRVh3eOZLcHKGI5vg+3FgsTi6KiFENePp6Ymnp+dN39++fTtt27a1Wd55551yO76fn5/1Lgq389JLL+Hu7m4d0NKyZUs++OAD/v73v3Pp0iWCg4PZvXs3ZrOZhx9+mJYtWzJ+/Hi8vb1xcrr7UaRRyjIOt5JJTU3Fy8uLlJSUW/6HUu6ObIYNw0GxQPgo6DMTZDJdIRwqOzubs2fPEhYWhsEg5+Sro1v9G5c2D6Tldyea94e/5p+IjlkEP73v0HKEEEKUTpnCb8GCBYSGhmIwGAgPD2fPnj033XbTpk106NABb29v3N3dadOmDV9++aXNNoqiMGXKFGrXro2rqysRERE2swRUam0GwyMfqs93fgg7P3ZsPUIIIW7L7vBbt24dEyZMYOrUqezfv5/WrVvTu3dv623lb+Tr68ubb75JdHQ0Bw8eZPjw4QwfPpwffyy84HT27NnMmzePRYsWERMTg7u7O7179yY7O7vs3+xu6vQCRExTn0e9AzFLHFqOEEKI21Ds1KlTJ2XMmDHW12azWQkODlZmzJhR6n20bdtWeeuttxRFURSLxaIEBQUpc+bMsb6fnJys6PV6Zc2aNaXaX0pKigIoKSkppa6hQvz3XUWZ6qku+79ybC1C1FBZWVnK0aNHlaysLEeXIirIrf6NS5sHdrX8TCYT+/btIyIiwrrOycmJiIgIoqOjSxO0REVFceLECXr06AHA2bNniYuLs9mnl5cX4eHhN91nTk4OqampNkul8MBbEP4P9fl3Y+FI6S8MFUIIcffYFX6JiYmYzWYCAwNt1gcGBhIXF3fTz6WkpGA0GnFxcaFfv358+umnPPTQQwDWz9mzzxkzZuDl5WVdQkJC7PkaFUejgT4zoO1z6gjQjX+Dk46ZT1AIIcTN3ZXRnh4eHhw4cIC9e/cyffp0JkyYUOYJWgEmT55MSkqKdSmvizrLhUYDj/4ftHgSLHmw7jl1NhghhBCVhl1zzPj7+6PVaomPj7dZHx8fT1BQ0E0/5+TkZJ1ip02bNhw7dowZM2bQq1cv6+fi4+Nt5neLj4+/6Szier2+Qm+geMectPD4YjBlqrPArB6oTowd0tHRlQkhhMDOlp+Liwvt27cnKirKus5isRAVFUXnzp1LvR+LxUJOTg4AYWFhBAUF2ewzNTWVmJgYu/ZZ6Wid4ekVENYTcjNg1ZNw5aCjqxJCCEEZuj0nTJjA0qVLWblyJceOHeMf//gHGRkZ1hstDhkyhMmTJ1u3nzFjBtu2bePPP//k2LFjfPTRR3z55Zc8++yzgDrh7Pjx43n//ff57rvvOHToEEOGDCE4OJj+/fuXz7d0FGcDDFoDIeGQnaLeC/DqSUdXJYQQNZ7d4TdgwAA+/PBDpkyZQps2bThw4ABbtmyxDliJjY3lypUr1u0zMjIYPXo0zZs3p2vXrmzcuJGvvvqKv/3tb9ZtXn/9dV588UVGjhxJx44dSU9PZ8uWLdVjaiIXdxj8NdRuDZmJ6h0hrp9zdFVCiEpo2LBhaDQaRo0aVey9MWPGoNFoGDZsmHXbWzUQQkND0Wg0aDQa3N3dadeuHevXr6+gyqsemdvzbslIghWPwNXj4F0fRmxR7xIvhChXVXluz2HDhvHTTz+RmprKlStXrJNKZ2dnU7t2bTw9Pbn//vtZsWIFw4YNIzk5mc2bN5e4r9DQUJ5//nleeOEFUlNT+eijj1i6dCm7du2iS5cud/FblT+Z27MqcfeD5zaDTxgkn1dbgOlXHV2VEKKSadeuHSEhIWzatMm6btOmTdSrV4+2bdvatS8PDw+CgoJo3LgxCxYswNXVle+//768S66SJPzuJs/a6qhPzzqQeBK+ehyykh1dlRDVn6KAKcMxSxk610aMGGFzH71ly5ZZx1WUlU6nw9nZGZPJdEf7qS4cfzvdmsanvhqAy/tC3CFY9ZTaItQbHV2ZENVXbiZ84KDTDG9cVs/92+HZZ59l8uTJnD9/HoDdu3ezdu3aMl8fbTKZ+Oijj0hJSeGBBx4o0z6qG2n5OYJ/IzXwDN5wcS+sGQi5WY6uSghRSdSqVYt+/fqxYsUKli9fTr9+/fD397d7PxMnTsRoNOLm5sasWbOYOXMm/fr1q4CKqx5p+TlKUAt4dhN88Ric2wlfD4UBX4HOxdGVCVH9OLupLTBHHbsMRowYwdixYwH1NnJl8dprrzFs2DCMRiOBgYFo5GbbVhJ+jlS3PQxeB189Cad+hG9GwpOfqzPECCHKj0Zjd9ejo/Xp0weTyYRGo6F3795l2oe/v791di1hS8LP0UK7wYBVatfnkW/UvxIfmw9O0iMtRE2m1Wo5duyY9XlJUlJSOHDggM06Pz+/yjPZfyUm4VcZNIqApz6H9cPgwCr1L9S+s9W/VoUQNdbtrlvevn17scsfnn/+eT777LOKLKtakIvcK5MDa2Bz/swO3SZAxFTH1iNEFVSVL3IXpSMXuVc3bQZBv4/U57s+hp0fObYeIYSopiT8KpuOf4OH3lWfR70LMYsdW48QQlRDEn6VUdeXoMfr6vP/vA77v3RsPUIIUc1I+FVW978B941Rn38/Dg5vuvX2QgghSk3Cr7LSaKD3dGg3FBQLbHoBTmxxdFVCCFEtSPhVZhoN/OUTaPk0WPJg3bPwzSi4/D9HVyaEEFWahF9l56SF/guh+eNgyYU/1sCSXvDZQ3BoA5hzHV2hEEJUORJ+VYHWGZ5eAX+LgpbPgJMzXNwDG5+HT1rAjtmQnuDoKoUQosqQ8KtK6naAJ5fCy0eg12RwD4D0OPh5OnzSHDb9HS7tc3SVQghR6Un4VUUegdBrkhqCT3wGdTqA2QQH18LSB+CzCDi4HvLkppVCCFESCb+qTOcCrZ6GF6Lgbz9BqwH5XaJ7YdPfYG4L2D4T0uIdXakQopTi4uJ48cUXadCgAXq9npCQEB599FGioqIACA0NRaPR8Ntvv9l8bvz48fTq1cv6etq0aWg0GkaNGmWz3YEDB9BoNJw7d66iv0qlJuFXXdRtD08sye8SfQOMgZAeD9tn5HeJjoSL0iUqRGV27tw52rdvz08//cScOXM4dOgQW7Zs4f7772fMmDHW7QwGAxMnTrzt/gwGA59//jmnTp2qyLKrJAm/6sYjEHpNhPGH1XsD1u2ojhI9uA4+ewCWPggHv5YuUSEqodGjR6PRaNizZw9PPvkkjRs3pnnz5kyYMMGmpTdy5Eh+++03fvjhh1vur0mTJtx///28+eabFV16lSO3NKqudC7Q8il1ubQPYpbAkU1w6XfY9DtsfQvaD4cOw8EjyNHVClGhFEUhKy/LIcd21bmW6g7q165dY8uWLUyfPh139+I33vX29rY+DwsLY9SoUUyePJk+ffrgdIv7f86cOZOOHTvy+++/06FDhzJ9h+pIwq8mqNMenlgMD78H+1bA3s/VUaI7Zqp3jmjeH8JHqaNJhaiGsvKyCF8d7pBjxwyOwc3Z7bbbnT59GkVRuPfee0u137feeovly5ezatUqnnvuuZtu165dO5555hkmTpxoPW8opNuzZjEGQM/X4eXD8NQyCAlXu0QPrYfPHoQl98Mf6yAvx9GVClHj2Htr1Vq1avHqq68yZcoUTKZbn8Z4//332blzJ1u3br2TEqsVafnVRFpnaPGkulz+n9olengDXN4P34yErW9ChxHqIl2iohpw1bkSMzjGYccujUaNGqHRaDh+/Hip9z1hwgT++c9/8s9//vOW2zVs2JAXXniBSZMm8fnnn5d6/9WZtPxquuC28PhCePkoPPAWeNSGjKuwY5Y6SnTD83BhD9j5V6kQlYlGo8HN2c0hS2nO9wH4+vrSu3dvFixYQEZGRrH3k5OTi60zGo28/fbbTJ8+nbS0tFvuf8qUKZw8eZK1a9eWqp7qTsJPqIy1oMdrMP4QPLUcQu5TJ9M+vAE+fwiW3g8H1kiXqBAVaMGCBZjNZjp16sTGjRs5deoUx44dY968eXTu3LnEz4wcORIvLy9Wr159y30HBgYyYcIE5s2bVxGlVzkSfsKW1hlaPAHP/wgjd0CbSNDq1e7RzaPU1uBP0yH1iqMrFaLaadCgAfv37+f+++/nlVdeoUWLFjz00ENERUWxcOHCEj/j7OzMe++9R3Z29m33/+qrr2I0Gsu77CpJo9h7lrUSSk1NxcvLi5SUFDw9PR1dTvWTkVg4SjTtsrrOSQfN/gqd/g4hndTbLwlRCWRnZ3P27FnCwsIwGAyOLkdUgFv9G5c2D8rU8luwYAGhoaEYDAbCw8PZs2fPTbddunQp3bt3x8fHBx8fHyIiIoptP2zYMDQajc3Sp0+fspQmKoK7P/R4FcYfVO8uUa9LfpfoRlj2MCzpCfu/lNagEKLKsHu057p165gwYQKLFi0iPDycuXPn0rt3b06cOEFAQECx7bdv386gQYPo0qULBoOBWbNm8fDDD3PkyBHq1Klj3a5Pnz4sX77c+lqv15fxK4kKo3VW7yvY/HG48gfsWaJOoH3lD/hurLqNTyjU6wz17lMf/RtLq1AIUenY3e0ZHh5Ox44dmT9/PgAWi4WQkBBefPFFJk2adNvPm81mfHx8mD9/PkOGDAHUll9ycjKbN2+2/xsg3Z4OlZEE+1fAkW8g/ggoFtv3XX3zgzA/DGu3Bp38YSMqjnR7Vn/l0e1pV8vPZDKxb98+Jk+ebF3n5OREREQE0dHRpdpHZmYmubm5+Pr62qzfvn07AQEB+Pj48MADD/D+++/j5+dX4j5ycnLIySkcdZiammrP1xDlyd0Pur+iLtkp6h0lYn9Tl4u/Q9Y1OPGDugDoDOqMMwVhWLcjuHo79CsIIWoeu8IvMTERs9lMYGCgzfrAwMBSX5g5ceJEgoODiYiIsK7r06cPTzzxBGFhYZw5c4Y33niDvn37Eh0djVarLbaPGTNm8M4779hTurgbDF5wT4S6gDp5dtxBiI0uDMTMRDi/W10A0EBg88IwrHcfeNV12FcQ1Uc1GMsnbqI8/m3v6gwvM2fOZO3atWzfvt2mqTpw4EDr85YtW9KqVSsaNmzI9u3befDBB4vtZ/LkyUyYMMH6OjU1lZCQkIotXthP56LOF1q3A3R5Ub1QPulMkTCMhmtnIP6wuuz9TP2cV4htV2mtpnCLiXuFKMrZ2RlQe5lcXUs3u4qoWjIzM4HCf+uysCv8/P390Wq1xMfb3hw1Pj6eoKBbT4P14YcfMnPmTP773//SqlWrW27boEED/P39OX36dInhp9frZUBMVaTRgP896tIufyLe9ITCVmFstDp4JuUCHLqgzjkKoPeCeuGFYRjcDpzlXI4omVarxdvbm4SEBADc3Eo/y4qo3BRFITMzk4SEBLy9vUvsGSwtu8LPxcWF9u3bExUVRf/+/QF1wEtUVBRjx4696edmz57N9OnT+fHHH0t1S42LFy+SlJRE7dq17SlPVEXGAGj2mLoA5KSrt2AqCMOLeyEnBU5tVRcArYs6LVtIeGFXqZvvzY8hapyCP8YLAlBUL97e3rdtcN2O3aM9161bx9ChQ1m8eDGdOnVi7ty5fP311xw/fpzAwECGDBlCnTp1mDFjBgCzZs1iypQprF69mq5du1r3YzQaMRqNpKen88477/Dkk08SFBTEmTNneP3110lLS+PQoUOlauHJaM9qzJyndokWhGFstHqH+hv5N7E9b+gTKpdYCMxmM7m5uY4uQ5QjZ2fnW7b4KmS0J8CAAQO4evUqU6ZMIS4ujjZt2rBlyxbrIJjY2FibGysuXLgQk8nEU089ZbOfqVOnMm3aNLRaLQcPHmTlypUkJycTHBzMww8/zHvvvSddmwK0Oghuoy73jVLPG14/VyQMf4PEE4XL/pXq54xBtmEY2ELdl6hRtFrtHXWNiepLpjcTVV9GElyIKQzDy/9T71NYlM5VDdA67dWlbgd1YI20DoWoVkqbBxJ+ovrJzYJL+wvD8MIe9bzhjdwD8oOwPdTpAHXaqZdrCCGqLAk/IQpYLJB0Gi79rg6mufi7eh7Rkld8W//GahAWBGJgc3VaNyFElSDhJ8St5GbBlYNqGF76XQ3E5PPFt9MZ1CnZrIHYHrzrS3epEJWUhJ8Q9kq/Cpf3q0FY0ErMLqm7tFb+ucP8QAxuJ1O0CVFJSPgJcacsFrj2Z2HL8NLvEHe4+GAaAL9G6iCaggE1gS3UGW6EEHeVhJ8QFSE3G+IOFQnEfXD9bPHttHq1u7RoIMq1h0JUuAq7zk+IGs3ZACEd1aVARpLtucNL+yA7GS7uUZcCbv5FLrXIf3T1uetfQQghLT8hyp+iqN2lRc8dXjlYcnepb0Pwb6TeycIrxPbRIwic5AJtIewhLT8hHEWjAb+G6tJ6gLouL0ftLi1oGV76XQ3Ia2fUpSROOvAMzg/DgmDMD0fv/Ncu7nfvewlRjUj4CXE36PSFt3cqkHlNnY0mORZSLqp3syh4TL2sXoeYHKsuN+PqUzwcvYu8dg+Q20EJUQIJPyEcxc0X7il+yy4ALGZIiysSigXBeBGS85/npEDWdXWJO1jyfrQu4FmneIuxaPeqs9zzTtQ8En5CVEZOWvCqoy6El7xNdgqkXLp5OKZdBrNJHY1a0ojUAm7+RVqN9WzD0b2W2rp0cZeRqqJakfAToqoyeKlLYLOS3zfnqQFYEIopFwqDseC1KR0yE9XlyoGbH8vJWQ1B6+J9w+si6w1F3jd4yaAdUSlJ+AlRXWl1akvOu17J7yuKekmGTYvxhnDMSFRHqVpyISNBXeyiUQPwloHpA4Yb3/NWz5MKUUEk/ISoqTSawrAJalnyNooCuZmF5xazkos8L2HJTi7cxpQO5AdsdjJct7M+Z/cbAtP7hsD0Ar2n7aPBU30u3bTiNiT8hBA3p9GoQeLirp4HtEeeKT8M7QnO/O1QIDdDXVIvlaFubWEQGjxB72UbjtZHrxueexW+rzNIgFZjEn5CiIqhcwFjgLrYw2KxHclqE5wFj9fUAT/Zqeq22amQk6quUyygmAs/W1ZOzjcJTG/bdUUD09oS9VBH0Tq7yTnPSkrCTwhRuTg5FXZt2ktRwJSRH4T5YZhT9PGG5wXvWZ/nP6Ko5zkLBgPdCa2+MAiLPrq4FVl34/tuJX/G2S3/czesk3tO2k3CTwhRfWg0oDeqi2dw2fZhsYApzTYQSxWiRdaZ0gv3Z85Rl+zkcvmKJXLSqedIiwVp0cDMX6czqNd/6vRqaGr1+a9d1MeCxd73tVUrTqpWtUIIUdGcnArP/5WVoqg3TM7NUgcMFXssaV2R7U2ZxdeV9FnFoh7Pkqd2/+aUcP/Ju0XjlB+C+aFoV3gWbO8CzfpDvZtc21qOJPyEEKK8aTRqa8vFDfCrmGMoijqJQdGQNGXcIlQzCp+bc/NbpCZ1YJK5yJKXU+T93PzXRd8veJ5zQz0WyMtWlzvh31jCTwghxE1oNGprSad3zK2xFEVtcd4qHG8XniW9H9TqrpQv4SeEEMJ+Gk1+t2XVHGwj070LIYSocST8hBBC1DgSfkIIIWocCT8hhBA1joSfEEKIGkfCTwghRI1TpvBbsGABoaGhGAwGwsPD2bNnz023Xbp0Kd27d8fHxwcfHx8iIiKKba8oClOmTKF27dq4uroSERHBqVOnylKaEEIIcVt2h9+6deuYMGECU6dOZf/+/bRu3ZrevXuTkFDyTS63b9/OoEGD+Pnnn4mOjiYkJISHH36YS5cKb1Mye/Zs5s2bx6JFi4iJicHd3Z3evXuTnX2HMwUIIYQQJdAoiqLY84Hw8HA6duzI/PnzAbBYLISEhPDiiy8yadKk237ebDbj4+PD/PnzGTJkCIqiEBwczCuvvMKrr74KQEpKCoGBgaxYsYKBAwfedp+pqal4eXmRkpKCp6enPV9HCCFENVLaPLCr5Wcymdi3bx8RERGFO3ByIiIigujo6FLtIzMzk9zcXHx9fQE4e/YscXFxNvv08vIiPDy81PsUQggh7GHX9GaJiYmYzWYCAwNt1gcGBnL8+PFS7WPixIkEBwdbwy4uLs66jxv3WfDejXJycsjJKZxUNTU1tdTfQQghhLiroz1nzpzJ2rVr+eabbzAYDGXez4wZM/Dy8rIuISEh5VilEEKI6s6u8PP390er1RIfH2+zPj4+nqCgoFt+9sMPP2TmzJls3bqVVq0KZ+0u+Jw9+5w8eTIpKSnW5cKFC/Z8DSGEEDWcXeHn4uJC+/btiYqKsq6zWCxERUXRuXPnm35u9uzZvPfee2zZsoUOHTrYvBcWFkZQUJDNPlNTU4mJibnpPvV6PZ6enjaLEEIIUVp239JowoQJDB06lA4dOtCpUyfmzp1LRkYGw4cPB2DIkCHUqVOHGTNmADBr1iymTJnC6tWrCQ0NtZ7HMxqNGI1GNBoN48eP5/3336dRo0aEhYXx9ttvExwcTP/+/cvvmwohhBD57A6/AQMGcPXqVaZMmUJcXBxt2rRhy5Yt1gErsbGxODkVNigXLlyIyWTiqaeestnP1KlTmTZtGgCvv/46GRkZjBw5kuTkZLp168aWLVvu6LygEEIIcTN2X+dXGcl1fkIIIaCCrvMTQgghqgMJPyGEEDWOhJ8QQogaR8JPCCFEjSPhJ4QQosaR8BNCCFHjSPgJIYSocST8hBBC1DgSfkIIIWocCT8hhBA1joSfEEKIGkfCr4ikrCSuZV9zdBlCCCEqmIRfvuy8bMb9PI7B/x7MmeQzji5HCCFEBZLwy3ct+xrXs69zKf0Sz/3wHL9e/tXRJQkhhKggEn75go3BrHpkFe0C2pGWm8bo/47m6xNfO7osIYQQFUDCrwgfgw9LH17Kow0exayYee+395i9dzZmi9nRpQkhhChHEn43cNG6ML3bdF5s+yIAXx79kvE/jyczN9PBlQkhhCgvEn4l0Gg0jGw1kjk956DX6tl+cTtDtwwlLiPO0aUJIYQoBxJ+t9AntA/Lei/D1+DL8WvHGfzvwRxJOuLosoQQQtwhCb/baFWrFav7reYe73u4mnWVYf8ZRtT5KEeXJYQQ4g5I+JVCHWMdvuz7JV3rdCXbnM3L219m2eFlKIri6NKEEEKUgYRfKRldjMx/YD6D7h2EgsIn+z5hWvQ0cs25ji5NCCGEnST87KBz0vFG+BtM6jQJJ40Tm05tYtR/R5GSk+Lo0oQQQthBwq8MIptG8ukDn+Kmc2NP3B6e/eFZYlNjHV2WEEKIUpLwK6MedXvwRd8vCHIP4lzqOQb/MJjf4353dFlCCCFKQcLvDjTxbcKafmto6d+SlJwUXtj2At+d+c7RZQkhhLgNCb875O/qz7Ley3i4/sPkWfJ4c9ebzNs/D4ticXRpQgghbkLCrxwYdAbm9JzDCy1fAGDpoaW8tuM1svOyHVyZEEKIkkj4lRMnjRPj2o3j/a7vo3PSsfX8Vkb8OILErERHlyaEEOIGEn7l7K/3/JUlDy3BS+/FocRDDP73YE5eP+nosoQQQhRRpvBbsGABoaGhGAwGwsPD2bNnz023PXLkCE8++SShoaFoNBrmzp1bbJtp06ah0WhslnvvvbcspVUKHYM6suqRVYR6hnIl4wpD/jOEnRd3OrosIYQQ+ewOv3Xr1jFhwgSmTp3K/v37ad26Nb179yYhIaHE7TMzM2nQoAEzZ84kKCjopvtt3rw5V65csS67du2yt7RKpb5nfb565Cs6BnUkIzeDsT+NZdWxVY4uSwghBGUIv48//pgXXniB4cOH06xZMxYtWoSbmxvLli0rcfuOHTsyZ84cBg4ciF6vv+l+dTodQUFB1sXf39/e0iodL70XiyMW8/g9j2NRLMzcM5MPYj4gz5Ln6NKEEKJGsyv8TCYT+/btIyIionAHTk5EREQQHR19R4WcOnWK4OBgGjRoQGRkJLGx1WPGFGetM+90eYfx7cYDsOb4Gl786UXSTemOLUwIIWowu8IvMTERs9lMYGCgzfrAwEDi4sp+o9fw8HBWrFjBli1bWLhwIWfPnqV79+6kpaWVuH1OTg6pqak2S2Wm0Wh4vuXzfNLrEwxaA7su7eK5/zzH5fTLji5NCCFqpEox2rNv3748/fTTtGrVit69e/PDDz+QnJzM119/XeL2M2bMwMvLy7qEhITc5YrLJqJ+BCv6rMDf1Z/TyacZ/O/BHLx60NFlCSFEjWNX+Pn7+6PVaomPj7dZHx8ff8vBLPby9vamcePGnD59usT3J0+eTEpKinW5cOFCuR27ojX3b86afmto4tOEpOwkRvw4gi3ntji6LCGEqFHsCj8XFxfat29PVFThncwtFgtRUVF07ty53IpKT0/nzJkz1K5du8T39Xo9np6eNktVEuQexMq+K+lZtyc55hxe2/EaSw4ukZvjCiHEXWJ3t+eECRNYunQpK1eu5NixY/zjH/8gIyOD4cOHAzBkyBAmT55s3d5kMnHgwAEOHDiAyWTi0qVLHDhwwKZV9+qrr7Jjxw7OnTvHr7/+yuOPP45Wq2XQoEHl8BUrJ3dnd/7v/v/j2abPAvDp/z7lrd1vYTKbHFyZEEJUfzp7PzBgwACuXr3KlClTiIuLo02bNmzZssU6CCY2NhYnp8JMvXz5Mm3btrW+/vDDD/nwww/p2bMn27dvB+DixYsMGjSIpKQkatWqRbdu3fjtt9+oVavWHX69yk3rpGVip4mEeYXxQcwHfHfmOy6mXWTu/XPxMfg4ujwhhKi2NEo16GtLTU3Fy8uLlJSUKtcFWuDXS7/yyo5XSM9NJ8QjhAUPLiDMK8zRZQkhRJVS2jyoFKM9BXSp04Uv+35JHWMdLqRdIPKHSGKuxDi6LCGEqJYk/CqRe3zuYdUjq2hdqzVppjRGbRvFplObHF2WEEJUOxJ+lYyfqx+f9/6cvmF9yVPymPrrVD7+/WO5Oa4QQpQjCb9KSK/VM6v7LP7R+h8ALD+ynAnbJ5CZm+ngyoQQonqQ8KukNBoNo9uMZkb3GTg7ORMVG8WwLcM4nHjY0aUJIUSVJ+FXyf2lwV/4vPfn+Oh9OHbtGIP+PYhXd7xKbGr1mPhbCCEcQcKvCmgb0JavH/2aRxs8igYNP577kb9u/isfxHxAUlaSo8sTQogqR67zq2JOXDvBJ/s/Yfel3QC46dwY1mIYQ5sNxc3ZzcHVCSGEY5U2DyT8qqiYKzF8vO9jjiYdBcDP4Mc/Wv+DJxo/gbOTs4OrE0IIx5DwqwEsioWt57byf/v/j4vpFwGo71mfcW3H8VD9h9BoNA6uUAgh7i4Jvxok15zL+pPrWXxwMdeyrwHQ0r8lL7d/mY5BHR1cnRBC3D0SfjVQuimdlUdXsvLISrLysgDoUbcHL7V7icY+jR1cnRBCVDwJvxosMSuRRX8sYsPJDZgVMxo0PNbwMca2HUuQe/nddFgIISobCT/BuZRzzPvfPLad3waAi5MLkU0jeb7l83jpvRxcnRBClD8JP2F18OpBPt73Mfvi9wHg4eLBCy1fYHDTwei1egdXJ4QQ5UfCT9hQFIVfLv7C3P1zOZ18GoAg9yDGthnLXxr8Ba2T1sEVCiHEnZPwEyUyW8x8d+Y7FhxYQHxmPACNfBoxvt14utfpLpdHCCGqNAk/cUvZedmsPr6azw59RpopDYAOgR2Y0H4CLWu1dHB1QghRNhJ+olRSclL47NBnrD62GpPFBMBD9R/ipXYvUd+zvoOrE0II+0j4CbtcSb/C/APz+f7M9ygo6DQ6nmz8JKNaj8Lf1d/R5QkhRKlI+IkyOXHtBHP3z2XXpV0AuOpcGdZ8GEObD8Xd2d3B1QkhxK1J+Ik7sufKHj7Z9wmHk9Sb5/oafBnVehRPNX5KJs4WQlRaEn7ijimKwtbzW5m3fx6xaerNc+t51OPFdi/Su35vGRkqhKh0JPxEucm15LLx5EYW/rHQOnF2C78WvNz+ZTrV7uTg6oQQopCEnyh3GbkZrDyykhVHVlgnzu5Wpxvj242niW8TB1cnhBASfqICFUycvfHkRvKUPDRo6NegH482fJQOgR1w0bo4ukQhRA0l4Scq3PnU88zbP4+t57da17np3Ogc3JkedXvQvU53arnVcmCFQoiaRsJP3DWHrh5i/cn17Ly0k8SsRJv3mvk1o0fdHvSs25Nmfs1w0jg5qEohRE0g4SfuOoti4VjSMX65+Au/XPzFeplEAT+DH93qdKNnSE861+6M0cXooEqFENWVhJ9wuMSsRHZe3MnOSzv59fKvZORmWN/TOeloH9CeHnV70KNuD0K9Qh1XqBCi2ihtHpSpD2rBggWEhoZiMBgIDw9nz549N932yJEjPPnkk4SGhqLRaJg7d+4d71NUDf6u/jze6HE+7vUxOwfsZOnDS3mu2XPU96xPniWPmLgY5vw+h0c3P0q/Tf2YtWcW0ZejyTXnOrp0IUQ1Z3f4rVu3jgkTJjB16lT2799P69at6d27NwkJCSVun5mZSYMGDZg5cyZBQUHlsk9R9Thrnbmv9n283vF1/vX4v/jX4//i9Y6vE147HJ2Tjti0WL469hUjt42k29puvPzzy3xz6pti5xCFEKI82N3tGR4eTseOHZk/fz4AFouFkJAQXnzxRSZNmnTLz4aGhjJ+/HjGjx9fbvsE6fas6tJN6fx25Td2XNzBzos7ScpOsnm/uV9z66CZpn5NZdCMEOKmSpsHOnt2ajKZ2LdvH5MnT7auc3JyIiIigujo6DIVWpZ95uTkkJOTY32dmppapmOLysHoYiSifgQR9SOsg2Z2XNzBLxd/4UjSEeuy8I+F+Bn86F63Oz3r9qRzcGeZbFsIUSZ2hV9iYiJms5nAwECb9YGBgRw/frxMBZRlnzNmzOCdd94p0/FE5eakcaK5f3Oa+zdndJvR1kEzv1z8hV8v/0pSdhKbT29m8+nN6qCZwPb0rNuTHnV7yP0HhRClZlf4VRaTJ09mwoQJ1tepqamEhITc8X4/33UWP3cX+rQIwuCsveP9iTtXMGjm8UaPk2vOZV/CPnZc2MHOSzs5n3qemCsxxFyJYfbe2dT3rG8dPdo+oD3OWrn7hBCiZHaFn7+/P1qtlvj4eJv18fHxNx3MUhH71Ov16PX6Mh3vZtJz8vh46wkyTGZ8vnfmyXZ1GRxejwa15Fq0yqJg0Mx9te9jIhM5l3JOvabw0i/si9/H+dTzfHn0S748+iXuzu50Ce5C9zrd6V63u9yQVwhhw67wc3FxoX379kRFRdG/f39AHZwSFRXF2LFjy1RAReyzLCyKwqieDVmzJ5bLKdl8tussn+06S+cGfkTeV4+HmwXhopOBFpVJqFcooV6hDGk+hHRTOtFXovnl4i/WQTPbzm9j2/ltANT3rE9L/5bWpYlvE5mDVIgazO7RnuvWrWPo0KEsXryYTp06MXfuXL7++muOHz9OYGAgQ4YMoU6dOsyYMQNQB7QcPXoUgEceeYTIyEgiIyMxGo3cc889pdrn7ZTnaE+zRWHHyQRW/RbLzycSsOT/dPyNLjzdIYRBHetRz8/tjo4hKpZFsXA06ah1ppkjSUeKbePs5ExT36a08G9By1otaeXfihCPELlHoRBVXIXO8DJ//nzmzJlDXFwcbdq0Yd68eYSHhwPQq1cvQkNDWbFiBQDnzp0jLCys2D569uzJ9u3bS7XP26moSx0uJWexbk8sa/deICGtcHRpj8a1GNypHhFNA9BppTVY2SVnJ3M46TCHrh7iUKK6JOckF9vOS+9FC/8WtPJvpYaif0t8DD53v2AhRJnJ9GblKNdsIepYAqv3xPLLyavW9YGeegZ0CGFAp3rU8XYt9+OKiqEoChfTLnIw8SCHEw9zMPEgx5OOY7KYim0b4hFiDcSWtVpyr++96LXle75ZCFF+JPwqSGxSJmv2xrL+9wskpqu/LJ00cH+TAAaH16NXkwC0TtJ1VtXkmnM5ef0kBxMPWluI51LPFdtO56SjiU8TWvq3pFUttYVY37O+XHgvRCUh4VfBTHkWth6NY3VMLL+eKZyRpI63KwM6hjCgYwiBnoa7UouoGCk5KRxJPGJtIR5KPMS17GvFtvNw8aCFX+G5wxb+LfBz9XNAxULcXEJaNqtjYjkVn06ovxuNAjy4J8DIPQHGanVpl4TfXfTn1XTW7Ill/b6LJGeqkzJrnTRENA0gMrw+3e7xx0lag1WeoihcSr9k7So9dPUQx64dI8ecU2zbOsY6tPRvqXaZ1mpFU9+mGHTyx5C4+w5dTGH57rN8f/Ayuebiv+41Gqjnq4Zho0AjjQKMNA70oGEtI64uVS8UJfwcIDvXzJbDcayKOc/ec9et6+v5ujGwUwhPtw+hloecL6pOci25nLp+ymYwzZ8pfxbbTqfR0cinkXqpRS31coswrzDpLhUVIs9sYevReJbtOsvv5wt/F7Wr581DzYK4eD2TU/HpnExIs/7BfiONBkJ83GgUYKRRoEdhKAa44+ZSeedHkfBzsJPxaayOiWXj/oukZecB4KzV8HDzICLD69G5gZ8Mq6+m0kxpHE48bNNCvHGybgCjs5Hmfs2p71mfQPdAgtyDCHILIsg9iAC3AGkpCrslZ5pYu/cCX0af51JyFgA6Jw1/aVWb4V3DaB3ibbO9oigkpps4lZDGqfj0Io/pXMsoPgCsQF0fVxrnB2JBMN4TYMRd7/hQlPCrJLJMZv518DKrYmI5cCHZur6BvzuDw+vxZLu6+LjLxdbVmaIoxGXE2QymOZp0lGxz9i0/56P3Icg9iED3QALd8sMxPyAL1smF+gLgdEIay3efY9P+S2TlmgHwdXchMrwez95Xv0zjD5LSczgZn87phDRO5gfj6YR060C/ktTxdqVRoNpCvCeg8NF4F0NRwq8SOnI5hdUxsWz+3yUyTOp/oC46J/q1rM3g8Hp0qO8jrcEaIs+Sx+nk0xxNOsql9EvEZ8QTlxmnPmbE3TYYC/gZ/NSALBqORV7XcquFs5PMcVodWSwKO05dZfnuczaXYDWt7cnwrqE81jq4QgayXMswcSo+jZMJ6ZyOT+NUQjon49NJTC9+7rtAsJfBpuv0nvxzix6G8v9vU8KvEkvPyeO7A5dZFXOeI5cLb8fUONDI4E71eLxdXbxc5RdWTaUoCqmmVOIy4ojLiCM+M976vGhAlnRd4o00aKjlWsvarVoQioHugdYu1lqutdA6Vb2BDTVVRk4em/ZfZPmv5/jzagagnp97qGkgw7uGcV8DX4f8EX09w8SphPRiXahFJwi5UW0vg7WFWNCF2jjwzkJRwq8KUBSFgxfV1uB3f1y2dlcYnJ14tFUwg8Pr0SbEW1qDohhFUbiec90ahHGZxYMyPjOePEvebfel1Wjxd/Uv1q0a5B6En8EPL72Xurh4yZ0yHOjCtUy+iD7H2r0XrOMIPPQ6nukYwtDOoZV22sXkTBOn81uHRYMxPrXkUJzY517+0athmY8n4VfFpGbnsvl/l1j1Wywn4tOs65vV9mRweD36t61zV/vNRdVnUSxcy75mE5A3Pk/ITCBPuX1AFnDTueGt98ZL74Wn3lN97uJVGJB6L+v7Bes99Z7S9VpGiqKw5+w1lu8+x9ajcda5hkP93BjeNYwn29etsr8XUrJyOZ0fhkWDcfrjLXiw6e3ndL4ZCb8qSlEU9sdeZ1VMLP86eAVTngUAdxctfVrUpmUdTxoHetA4yAN/o1w2Ie6M2WImKTupxFZjXEYcyTnJJOckk5qTikLZf1UYnY1qELp4FoZjkRalt6F4iHq6eKJzqpq/2O9Udq6Z7/+4zPLd5zh6pfDUSPdG/gzvGkqvxgHV9tphRVHuqLdLwq8aSM40sXH/JVbFnLf27Rfl6+5CowAjTYI81L7y/L5zGT0qyptFsZBmSiMlJ4WUnBSSc5JJMaVYXxddl5qTqj7PSSHNlHZHoenh7FHYwizSmvTSe+Hh4oG7s3vxReeOm7Mb7s7u6LX6KnXaICEtm69+i2V1zHnrqEqDsxOPt63L8K6hNA70cHCFlZ+EXzWiKAoxZ6+x89RVTsanczI+jdhrmdzsX66Wh57GgUYaBXjQJEg9gdwo0APPChhZJcStmC1mNTRNKdZAtC6mFJKziwdmikkNzfKg0+isQXjj4qa7yXpnN4zORutzd507RhcjrjrXCpuU4NDFFJbtPsu/iszCUtvLwJDOoQzsGCJ/0NpBwq+ayzKZOXM1nRNxaZzM7ys/EZdmvbC1JLXzhxs3DjDSOMjDOsKqMlyYKkRReZY80kxp1kBMNaXahGdyTjLpuelk5GZYl8zcTDJyM0jPTScr7+b/H9yJkgLTGq46d9xdClueBp0BV50rrlpXDDqD9bVBZ8BV64pO48KuU6l8FX2ZfeeTrcdoX9+H4V1D6d08CGe5ZZrdJPxqqPScPHVkVVwaJ/OvxTkVn8aVlJtfN1bH2zW/69RI4/zWYlWd109UT3lmC1dSsom9lsn5pExir2UCEOChJ9DTQICnngAPPQEeBlxdtFgUizUMrUteYUgWBGfRwLRun1d8G7NirtDvp1iccXEy4Kl3w8vgroaltkhY5j8WrLO+zl/npnMrfJ0frkW30Wv1NWYqPQk/YaNgZNXJ/BbiqfznV29yDU7BZLeN86+7UVuJ6rx+ep2Eoih/maY8a7hdyH88fy2T2KQMLl7PIs9Sul9VHgadGogeems41vLQE+BpIDD/McBDX+oeD0VRyDHn2AbkDaF6Y4hm5maSZc4iOy9bXczZpGRncD0rQ22VanLROJV+lG15cNW5YtAa0Ov0ODs5Wxedk059rnW2WV+wzvp+0e21JXy+pH1ondFpdCWuL+nz5XG9qYSfKJXrGSZrC9HaWoxP4/pNJrvVOmmo7+dG4wCP/K5TNRjD/N2li0bcUsE8krHXMom9lqG24AoC7lrmTf8QK+CicyLEx5X6fu7U83VDo4GEtByupuYQn5ZNfGo22bmWUtdj1OvUgPRUW4xFW5G1Cp576DHqdWUeNFMwC8uyXWfZeSrRur5pbU+Gdgnhoea+KBqTTUhm5WWRlZdV+Do3y7q+xG2KrMvOy3/M/1xpJkKoTJw0TrwZ/ibPNHmmzPsobR7IyZ4azsfdhfAGfoQ3KLz/nHWy2/i0YsGYmp3Hn1cz+PNqBluOxNnsy1mrwVnrhLPWCRedEy5aJ+s6F13+eq0TzjpN/ntOOOdvV7C+YJuC7Z3z96Ev+rrgM7qSjqduX/S1Tqv+4lIAxQIKCoqivrYoBc/zH4s8L3gPm+3Un4/aCClhP/mfU3+O6r4sivqZgs8W7kd97eqixV2vw6jX4a7X4easrbLD2HPNFi4nZ9m02oq25gqm9bsZbzdn6vm6Uc/Xjfp+btT3daeen/o6yNNwy5+Loiik5eSRkJpDQlq29TE+NYeEtBwSUrNJSMshPjWbTJOZ9Jw80nPy+DOx+EjqolydtQQWBGSRx8AioRngacDTUBiSGTl5bNx/kRW7z1n374hZWMwWMznmHJtAzDHnkGvJtS55ljxyzTe8Lni/yPqC13lKXonri322hH0UvF9wzBuvMbUolrt2eYu0/ESpKYpCQlqOOsgmPs16S5RT8emk59zdLpzqzs0mELW4uxSGo7reNjCt61x0NuuNeh0GZ6dy/UWbnpPH+aQMYvPPvakhl8n5axlcTs7GfIvuSY0Ggr1creFWEGwFIXe3pvVLz8kjIbUgGLO5mh+KCUUer6bmkGbHf9d6nZM1HE/Gp1WpWVgcxaJYCgMzPwzddG64OZf95yTdnuKuURSFaxkmTGYLuXkKJrMFU56FXLO6FL5WrOtyCt7PX1/sM3kWTPnb2+5LwZRntu5L3a5gX7brTGbLTS8HuZFGAxpAo9HgpFHnxESD9blGA04aDRrIX68p9hms29l+xrr/IvvQ5H8eIDu/FZJhMt8yOMrKSYM1FN312hsCMz9c9TqMNwSnm15LUrqJ2KQMa9dkbFImSbe41Q2o16WprTd3m5Cr7+tGHR/XKnXOONNU0JIsDMWCFqS1VZmaTWp28ZAM83dnWJfQKj0LS1Uk3Z7irtFoNPhV0tlmzBY1EKEg4DQ3hBCV5iJoRVHIybOoQZjfJZeRYy7yXH3MNN24Tn2dYSpcl5FjJsOUl98NC2k5eXa1Ym7Hz92FEGvXpBv1/AqDLsCjal1YfituLjpC/XWE+rvfcrvsXLNNN6u3mzOdG/hV2e7rmkDCT1RrWidNlbljgUajweCsxeCsLZep6ywWhaxcs02QquFZcrCq4WkuErJ5eLu6FOmaLOymrIhb0VRlBmet+rORbs0qQ8JPiGrKyUlj7d4McHQxQlQyMjZdCCFEjSPhJ4QQosaR8BNCCFHjSPgJIYSocST8hBBC1DgSfkIIIWocCT8hhBA1TrW4zq9ghrbU1FQHVyKEEMKRCnLgdjN3VovwS0tLAyAkJMTBlQghhKgM0tLS8PLyuun71WJia4vFwuXLl/Hw8Kg2cwreKDU1lZCQEC5cuCCTd9tJfnZlIz+3spGfW9mU189NURTS0tIIDg7GyenmZ/aqRcvPycmJunXrOrqMu8LT01P+hyoj+dmVjfzcykZ+bmVTHj+3W7X4CsiAFyGEEDWOhJ8QQogaR8KvitDr9UydOhW9vnLeN68yk59d2cjPrWzk51Y2d/vnVi0GvAghhBD2kJafEEKIGkfCTwghRI0j4SeEEKLGkfATQghR40j4VXIzZsygY8eOeHh4EBAQQP/+/Tlx4oSjy6pyZs6ciUajYfz48Y4updK7dOkSzz77LH5+fri6utKyZUt+//13R5dV6ZnNZt5++23CwsJwdXWlYcOGvPfee7edY7Km+eWXX3j00UcJDg5Go9GwefNmm/cVRWHKlCnUrl0bV1dXIiIiOHXqVLnXIeFXye3YsYMxY8bw22+/sW3bNnJzc3n44YfJyMhwdGlVxt69e1m8eDGtWrVydCmV3vXr1+natSvOzs785z//4ejRo3z00Uf4+Pg4urRKb9asWSxcuJD58+dz7NgxZs2axezZs/n0008dXVqlkpGRQevWrVmwYEGJ78+ePZt58+axaNEiYmJicHd3p3fv3mRnZ5dvIYqoUhISEhRA2bFjh6NLqRLS0tKURo0aKdu2bVN69uypvPTSS44uqVKbOHGi0q1bN0eXUSX169dPGTFihM26J554QomMjHRQRZUfoHzzzTfW1xaLRQkKClLmzJljXZecnKzo9XplzZo15XpsaflVMSkpKQD4+vo6uJKqYcyYMfTr14+IiAhHl1IlfPfdd3To0IGnn36agIAA2rZty9KlSx1dVpXQpUsXoqKiOHnyJAB//PEHu3btom/fvg6urOo4e/YscXFxNv+/enl5ER4eTnR0dLkeq1pMbF1TWCwWxo8fT9euXWnRooWjy6n01q5dy/79+9m7d6+jS6ky/vzzTxYuXMiECRN444032Lt3L+PGjcPFxYWhQ4c6urxKbdKkSaSmpnLvvfei1Woxm81Mnz6dyMhIR5dWZcTFxQEQGBhosz4wMND6XnmR8KtCxowZw+HDh9m1a5ejS6n0Lly4wEsvvcS2bdswGAyOLqfKsFgsdOjQgQ8++ACAtm3bcvjwYRYtWiThdxtff/01q1atYvXq1TRv3pwDBw4wfvx4goOD5WdXCUm3ZxUxduxY/vWvf/Hzzz/XmNs33Yl9+/aRkJBAu3bt0Ol06HQ6duzYwbx589DpdJjNZkeXWCnVrl2bZs2a2axr2rQpsbGxDqqo6njttdeYNGkSAwcOpGXLljz33HO8/PLLzJgxw9GlVRlBQUEAxMfH26yPj4+3vldeJPwqOUVRGDt2LN988w0//fQTYWFhji6pSnjwwQc5dOgQBw4csC4dOnQgMjKSAwcOoNVqHV1ipdS1a9dil9KcPHmS+vXrO6iiqiMzM7PYzVO1Wi0Wi8VBFVU9YWFhBAUFERUVZV2XmppKTEwMnTt3LtdjSbdnJTdmzBhWr17Nt99+i4eHh7Xf28vLC1dXVwdXV3l5eHgUOy/q7u6On5+fnC+9hZdffpkuXbrwwQcf8Mwzz7Bnzx6WLFnCkiVLHF1apffoo48yffp06tWrR/Pmzfnf//7Hxx9/zIgRIxxdWqWSnp7O6dOnra/Pnj3LgQMH8PX1pV69eowfP57333+fRo0aERYWxttvv01wcDD9+/cv30LKdeyoKHdAicvy5csdXVqVI5c6lM7333+vtGjRQtHr9cq9996rLFmyxNElVQmpqanKSy+9pNSrV08xGAxKgwYNlDfffFPJyclxdGmVys8//1zi77ShQ4cqiqJe7vD2228rgYGBil6vVx588EHlxIkT5V6H3NJICCFEjSPn/IQQQtQ4En5CCCFqHAk/IYQQNY6EnxBCiBpHwk8IIUSNI+EnhBCixpHwE0IIUeNI+AkhhKhxJPyEEELUOBJ+QgghahwJPyGEEDWOhJ8QQoga5/8BVlYZV8pXGqEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create a dictionary to store the validation loss and accuracy of the models\n",
        "data = {\"Model\": [\"MLP-Mixer\", \"MLP\", \"CNN\"],\n",
        "        \"Validation Loss\": [lossv[-1], mlp_lossv[-1], cnn_lossv[-1]],\n",
        "        \"Validation Accuracy\": [accv[-1], mlp_accv[-1], cnn_accv[-1]]}\n",
        "\n",
        "# create a pandas dataframe using the dictionary\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# print the dataframe\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq9ZkLAP-9ab",
        "outputId": "ee82537b-c993-4798-f9ca-a96e7dcad776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Model  Validation Loss Validation Accuracy\n",
            "0  MLP-Mixer         0.081114     tensor(97.7900)\n",
            "1        MLP         0.216448     tensor(93.8300)\n",
            "2        CNN         0.071001     tensor(97.7500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through this comparison, we observe that MLP-Mixer performs  better to that of simple MLP model and CNN model."
      ],
      "metadata": {
        "id": "z9A_FnQTInNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation Study of the MLP-Mixer model"
      ],
      "metadata": {
        "id": "e-CiRjQQFjSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ablation study is a technique used to understand the importance of individual components of a model. We remove or change one or more components and observe the effect on the performance of the model. In this code, the MLP-Mixer model is implemented and trained for image classification. In the ablation study, I have removed one of the two types of mixers, token mixer or channel mixer, and observe the effect on the performance of the model.\n",
        "\n",
        "Here is the ablation study for MLP-Mixer model:\n",
        "\n",
        "##Token mixer only: Remove the channel mixer and keep only the token mixer in the MixerBlock."
      ],
      "metadata": {
        "id": "vS_jO_6M_ask"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenMixerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_patches):\n",
        "        super().__init__()\n",
        "        self.pre_layer_norm = nn.LayerNorm(dim)\n",
        "        self.post_layer_norm = nn.LayerNorm(dim)\n",
        "\n",
        "        self.token_mixer = nn.Sequential(\n",
        "            nn.Linear(num_patches, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(dim, num_patches),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        pre_ln = self.pre_layer_norm(x)\n",
        "        tm_out = self.token_mixer(pre_ln.transpose(1, 2)).transpose(1, 2)\n",
        "        tm_out = tm_out + x\n",
        "        post_ln = self.post_layer_norm(tm_out)\n",
        "        return post_ln\n",
        "\n",
        "\n",
        "class MLPTMixer(nn.Module):\n",
        "    def __init__(self, input_size, patch_size, dim=512, img_channel=1, layers=12, num_classes=10):\n",
        "        super().__init__()\n",
        "        assert (input_size[0] % patch_size[0]) == 0, 'H must be divisible by patch size'\n",
        "        assert (input_size[1] % patch_size[1]) == 0, 'W must be divisible by patch size'\n",
        "        num_patches = int(input_size[0] / patch_size[0] * input_size[1] / patch_size[1])\n",
        "        patch_dim = img_channel * patch_size[0] * patch_size[1]\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_size[0], p2=patch_size[1]),\n",
        "            nn.Linear(patch_dim, dim))\n",
        "\n",
        "        self.network = nn.Sequential(*[nn.Sequential(TokenMixerBlock(dim, num_patches)) for _ in range(layers)])\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.classifier = nn.Linear(dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.to_patch_embedding(x)\n",
        "        x = self.network(x)\n",
        "        return self.classifier(self.pool(x.transpose(1, 2)).squeeze(2))"
      ],
      "metadata": {
        "id": "dISMT0Ks_o7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition , I have used best patch size , dimension, layers and epochs obtained from Model tuning above for the comparison."
      ],
      "metadata": {
        "id": "3IOxG1qR_2nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_patch_size = (14, 14)\n",
        "best_dim = 128\n",
        "best_layers = 10\n",
        "best_epochs = 10\n",
        "\n",
        "model = MLPTMixer(input_size=(28, 28), patch_size=best_patch_size, dim=best_dim, img_channel=1, layers=best_layers, num_classes=10).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "lossv, accv = [], []\n",
        "for epoch in range(1, best_epochs + 1):\n",
        "    train(epoch)\n",
        "    validate(lossv, accv)\n",
        "\n",
        "# Save the trained model\n",
        "model_save_path = \"mnist_mlp_token_mixer_only.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of8HTkhW_0TZ",
        "outputId": "5b0fbe12-d10a-4729-a83c-9adfd588657b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.354990\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.164322\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.277929\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.120877\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.108617\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.049710\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.099665\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.172070\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.153646\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.210719\n",
            "\n",
            "Validation set: Average loss: 0.1140, Accuracy: 9643/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.023625\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.152303\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.081576\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.124300\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.094518\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.087316\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.025865\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.017202\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.126495\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.402873\n",
            "\n",
            "Validation set: Average loss: 0.0843, Accuracy: 9742/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.013841\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.067699\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.182087\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.029086\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.249071\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.025035\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.023719\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.170668\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.116220\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.070714\n",
            "\n",
            "Validation set: Average loss: 0.0840, Accuracy: 9735/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.030401\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.015056\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.005652\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.011606\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.005195\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.045196\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.062506\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.009468\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.015937\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.014922\n",
            "\n",
            "Validation set: Average loss: 0.0867, Accuracy: 9749/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.037117\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.003919\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.081663\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.002944\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.139719\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.093259\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.003612\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.009481\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.041825\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.025998\n",
            "\n",
            "Validation set: Average loss: 0.0824, Accuracy: 9744/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.022802\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.002916\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.005274\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.006153\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.082329\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.059159\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.012555\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.003041\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.152685\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.007175\n",
            "\n",
            "Validation set: Average loss: 0.0794, Accuracy: 9747/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.008777\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.005036\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.003691\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.019272\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.037360\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.133363\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.105991\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.021319\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.021081\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.001825\n",
            "\n",
            "Validation set: Average loss: 0.0835, Accuracy: 9760/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.012570\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.030068\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.007768\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.090469\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.004356\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.282021\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.038647\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.023546\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.043522\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.061197\n",
            "\n",
            "Validation set: Average loss: 0.0832, Accuracy: 9758/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.005363\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.034645\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.003612\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.020695\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.035996\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.032255\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.037604\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.005411\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.042185\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.073840\n",
            "\n",
            "Validation set: Average loss: 0.0795, Accuracy: 9774/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.025043\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.115569\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.097513\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.008126\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.105236\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.003753\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.016192\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.044300\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.142788\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.009004\n",
            "\n",
            "Validation set: Average loss: 0.0840, Accuracy: 9763/10000 (98%)\n",
            "\n",
            "Model saved to mnist_mlp_token_mixer_only.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Channel mixer only: Remove the token mixer and keep only the channel mixer in the MixerBlock.\n"
      ],
      "metadata": {
        "id": "bV77r_-0AoS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChannelMixerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_patches):\n",
        "        super().__init__()\n",
        "        self.pre_layer_norm = nn.LayerNorm(dim)\n",
        "        self.post_layer_norm = nn.LayerNorm(dim)\n",
        "\n",
        "        self.channel_mixer = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.Dropout(0.1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        pre_ln = self.pre_layer_norm(x)\n",
        "        cm_out = self.channel_mixer(pre_ln) + x\n",
        "        post_ln = self.post_layer_norm(cm_out)\n",
        "        return post_ln\n"
      ],
      "metadata": {
        "id": "8-exlWcaAuST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPCMixer(nn.Module):\n",
        "    def __init__(self, input_size, patch_size, dim=512, img_channel=1, layers=12, num_classes=10):\n",
        "        super().__init__()\n",
        "        assert (input_size[0] % patch_size[0]) == 0, 'H must be divisible by patch size'\n",
        "        assert (input_size[1] % patch_size[1]) == 0, 'W must be divisible by patch size'\n",
        "        num_patches = int(input_size[0] / patch_size[0] * input_size[1] / patch_size[1])\n",
        "        patch_dim = img_channel * patch_size[0] * patch_size[1]\n",
        "        self.to_patch_embedding = nn.Sequential(\n",
        "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_size[0], p2=patch_size[1]),\n",
        "            nn.Linear(patch_dim, dim))\n",
        "\n",
        "        self.network = nn.Sequential(*[nn.Sequential(ChannelMixerBlock(dim, num_patches)) for _ in range(layers)])\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.classifier = nn.Linear(dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.to_patch_embedding(x)\n",
        "        x = self.network(x)\n",
        "        return self.classifier(self.pool(x.transpose(1, 2)).squeeeze(2))"
      ],
      "metadata": {
        "id": "MaDSjnGYBqSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_patch_size = (14, 14)\n",
        "best_dim = 128\n",
        "best_layers = 10\n",
        "best_epochs = 10\n",
        "\n",
        "model = MLPTMixer(input_size=(28, 28), patch_size=best_patch_size, dim=best_dim, img_channel=1, layers=best_layers, num_classes=10).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "lossv, accv = [], []\n",
        "for epoch in range(1, best_epochs + 1):\n",
        "    train(epoch)\n",
        "    validate(lossv, accv)\n",
        "\n",
        "# Save the trained model\n",
        "model_save_path = \"mnist_mlp_channel_mixer_only.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7geNA99kB2Tn",
        "outputId": "475fa68e-fa0d-4be2-e1df-396933a893d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.393345\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.320428\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.224263\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.406623\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.246217\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.043794\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.145979\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.072148\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.128796\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.068564\n",
            "\n",
            "Validation set: Average loss: 0.1237, Accuracy: 9603/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.146540\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.145875\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.205374\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.194797\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.149268\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.043289\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.024406\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.035911\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.262414\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.189895\n",
            "\n",
            "Validation set: Average loss: 0.0974, Accuracy: 9688/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.041079\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.112544\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.107261\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.031587\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.199861\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.037480\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.057910\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.189024\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.072782\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.040533\n",
            "\n",
            "Validation set: Average loss: 0.0863, Accuracy: 9732/10000 (97%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.030635\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.056692\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.020125\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.204374\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.025964\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.078243\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.013880\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.079244\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.113372\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.043144\n",
            "\n",
            "Validation set: Average loss: 0.0871, Accuracy: 9727/10000 (97%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.086397\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.057407\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.012318\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.004507\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.099502\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.143523\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.080579\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.036606\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.136883\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.033686\n",
            "\n",
            "Validation set: Average loss: 0.1024, Accuracy: 9680/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.018308\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.006442\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.056273\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.059436\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.016778\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.016364\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.008778\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.023012\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.012809\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.008548\n",
            "\n",
            "Validation set: Average loss: 0.0828, Accuracy: 9731/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.028978\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.016491\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.010156\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.009281\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.025899\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.007602\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.011494\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.012173\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.132133\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.040792\n",
            "\n",
            "Validation set: Average loss: 0.0856, Accuracy: 9743/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.073295\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.036515\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000859\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.004765\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.072503\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.058664\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.004974\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.004511\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.081375\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.016463\n",
            "\n",
            "Validation set: Average loss: 0.0781, Accuracy: 9748/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.008636\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.036499\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.009675\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.023051\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.008187\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.010385\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.001407\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.006432\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.013951\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.012164\n",
            "\n",
            "Validation set: Average loss: 0.0824, Accuracy: 9767/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.001552\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.019165\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.028293\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.033805\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.007220\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.071070\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.078358\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.015675\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000803\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.009538\n",
            "\n",
            "Validation set: Average loss: 0.0804, Accuracy: 9757/10000 (98%)\n",
            "\n",
            "Model saved to mnist_mlp_channel_mixer_only.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the results of the ablation study above, it appears that the original MLP-mixer model performed better (97.79%) than the modified versions that only included the Token (97.63%) or Channel mixers (97.57%).\n",
        "\n",
        "The slight decrease in accuracy for the modified models suggests that both the Token and Channel mixers may have played a role in improving the performance of the original model. This highlights the importance of the overall architecture and the interplay between different components of the model.\n",
        "\n",
        "However, it's important to note that the differences in accuracy between the original and modified models are relatively small, and may not be statistically significant. Therefore, further experimentation and analysis may be needed to confirm the importance of the Token and Channel mixers in the MLP-mixer architecture."
      ],
      "metadata": {
        "id": "ld95CJSTFse6"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}